{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "76c3e402",
   "metadata": {},
   "source": [
    "# 自定义中间件\n",
    "通过实现能在智能体执行流程特定节点运行的钩子函数，即可构建自定义中间件。\n",
    "\n",
    "## 钩子函数\n",
    "中间件提供两种类型的钩子函数，用于拦截智能体的执行过程：\n",
    "\n",
    "<CardGroup cols={2}>\n",
    "  <Card title=\"节点式钩子函数\" icon=\"share-nodes\" href=\"#node-style-hooks\">\n",
    "    在特定执行节点按顺序运行。\n",
    "  </Card>\n",
    "\n",
    "  <Card title=\"包装式钩子函数\" icon=\"container-storage\" href=\"#wrap-style-hooks\">\n",
    "    围绕每次模型调用或工具调用运行。\n",
    "  </Card>\n",
    "</CardGroup>\n",
    "\n",
    "### 节点式钩子函数\n",
    "在特定执行节点按顺序运行，适用于日志记录、参数校验和状态更新场景。\n",
    "\n",
    "**可用钩子函数：**\n",
    "* `before_agent` - 智能体启动前执行（每次调用仅执行一次）\n",
    "* `before_model` - 每次模型调用前执行\n",
    "* `after_model` - 每次模型返回响应后执行\n",
    "* `after_agent` - 智能体执行完成后执行（每次调用仅执行一次）\n",
    "\n",
    "**代码示例：**\n",
    "\n",
    "<Tabs>\n",
    "  <Tab title=\"装饰器写法\">\n",
    "    ```python  theme={null}\n",
    "    from langchain.agents.middleware import before_model, after_model, AgentState\n",
    "    from langchain.messages import AIMessage\n",
    "    from langgraph.runtime import Runtime\n",
    "    from typing import Any\n",
    "\n",
    "\n",
    "    @before_model(can_jump_to=[\"end\"])\n",
    "    def check_message_limit(state: AgentState, runtime: Runtime) -> dict[str, Any] | None:\n",
    "        if len(state[\"messages\"]) >= 50:\n",
    "            return {\n",
    "                \"messages\": [AIMessage(\"对话已达到消息数量上限。\")],\n",
    "                \"jump_to\": \"end\"\n",
    "            }\n",
    "        return None\n",
    "\n",
    "    @after_model\n",
    "    def log_response(state: AgentState, runtime: Runtime) -> dict[str, Any] | None:\n",
    "        print(f\"模型返回结果: {state['messages'][-1].content}\")\n",
    "        return None\n",
    "    ```\n",
    "  </Tab>\n",
    "\n",
    "  <Tab title=\"类写法\">\n",
    "    ```python  theme={null}\n",
    "    from langchain.agents.middleware import AgentMiddleware, AgentState, hook_config\n",
    "    from langchain.messages import AIMessage\n",
    "    from langgraph.runtime import Runtime\n",
    "    from typing import Any\n",
    "\n",
    "    class MessageLimitMiddleware(AgentMiddleware):\n",
    "        def __init__(self, max_messages: int = 50):\n",
    "            super().__init__()\n",
    "            self.max_messages = max_messages\n",
    "\n",
    "        @hook_config(can_jump_to=[\"end\"])\n",
    "        def before_model(self, state: AgentState, runtime: Runtime) -> dict[str, Any] | None:\n",
    "            if len(state[\"messages\"]) == self.max_messages:\n",
    "                return {\n",
    "                    \"messages\": [AIMessage(\"对话已达到消息数量上限。\")],\n",
    "                    \"jump_to\": \"end\"\n",
    "                }\n",
    "            return None\n",
    "\n",
    "        def after_model(self, state: AgentState, runtime: Runtime) -> dict[str, Any] | None:\n",
    "            print(f\"模型返回结果: {state['messages'][-1].content}\")\n",
    "            return None\n",
    "    ```\n",
    "  </Tab>\n",
    "</Tabs>\n",
    "\n",
    "### 包装式钩子函数\n",
    "拦截执行流程并控制处理器的调用时机，适用于重试、缓存和数据转换场景。\n",
    "\n",
    "你可以决定处理器的调用次数：零次（短路执行）、一次（正常流程）或多次（重试逻辑）。\n",
    "\n",
    "**可用钩子函数：**\n",
    "* `wrap_model_call` - 围绕每次模型调用执行\n",
    "* `wrap_tool_call` - 围绕每次工具调用执行\n",
    "\n",
    "**代码示例：**\n",
    "\n",
    "<Tabs>\n",
    "  <Tab title=\"装饰器写法\">\n",
    "    ```python  theme={null}\n",
    "    from langchain.agents.middleware import wrap_model_call, ModelRequest, ModelResponse\n",
    "    from typing import Callable\n",
    "\n",
    "\n",
    "    @wrap_model_call\n",
    "    def retry_model(\n",
    "        request: ModelRequest,\n",
    "        handler: Callable[[ModelRequest], ModelResponse],\n",
    "    ) -> ModelResponse:\n",
    "        for attempt in range(3):\n",
    "            try:\n",
    "                return handler(request)\n",
    "            except Exception as e:\n",
    "                if attempt == 2:\n",
    "                    raise\n",
    "                print(f\"调用失败，正在进行第 {attempt + 1}/3 次重试，错误信息: {e}\")\n",
    "    ```\n",
    "  </Tab>\n",
    "\n",
    "  <Tab title=\"类写法\">\n",
    "    ```python  theme={null}\n",
    "    from langchain.agents.middleware import AgentMiddleware, ModelRequest, ModelResponse\n",
    "    from typing import Callable\n",
    "\n",
    "    class RetryMiddleware(AgentMiddleware):\n",
    "        def __init__(self, max_retries: int = 3):\n",
    "            super().__init__()\n",
    "            self.max_retries = max_retries\n",
    "\n",
    "        def wrap_model_call(\n",
    "            self,\n",
    "            request: ModelRequest,\n",
    "            handler: Callable[[ModelRequest], ModelResponse],\n",
    "        ) -> ModelResponse:\n",
    "            for attempt in range(self.max_retries):\n",
    "                try:\n",
    "                    return handler(request)\n",
    "                except Exception as e:\n",
    "                    if attempt == self.max_retries - 1:\n",
    "                        raise\n",
    "                    print(f\"调用失败，正在进行第 {attempt + 1}/{self.max_retries} 次重试，错误信息: {e}\")\n",
    "    ```\n",
    "  </Tab>\n",
    "</Tabs>\n",
    "\n",
    "## 创建中间件\n",
    "创建中间件有两种方式：\n",
    "\n",
    "<CardGroup cols={2}>\n",
    "  <Card title=\"基于装饰器的中间件\" icon=\"at\" href=\"#decorator-based-middleware\">\n",
    "    适用于单一钩子函数的简单场景，通过装饰器包装独立函数实现。\n",
    "  </Card>\n",
    "\n",
    "  <Card title=\"基于类的中间件\" icon=\"brackets-curly\" href=\"#class-based-middleware\">\n",
    "    适用于包含多个钩子函数或需要复杂配置的场景，功能更强大。\n",
    "  </Card>\n",
    "</CardGroup>\n",
    "\n",
    "### 基于装饰器的中间件\n",
    "适用于单一钩子函数的简单场景，通过装饰器包装独立函数即可实现。\n",
    "\n",
    "**可用装饰器：**\n",
    "**节点式：**\n",
    "* [`@before_agent`](https://reference.langchain.com/python/langchain/middleware/#langchain.agents.middleware.before_agent) - 智能体启动前执行（每次调用仅执行一次）\n",
    "* [`@before_model`](https://reference.langchain.com/python/langchain/middleware/#langchain.agents.middleware.before_model) - 每次模型调用前执行\n",
    "* [`@after_model`](https://reference.langchain.com/python/langchain/middleware/#langchain.agents.middleware.after_model) - 每次模型返回响应后执行\n",
    "* [`@after_agent`](https://reference.langchain.com/python/langchain/middleware/#langchain.agents.middleware.after_agent) - 智能体执行完成后执行（每次调用仅执行一次）\n",
    "\n",
    "**包装式：**\n",
    "* [`@wrap_model_call`](https://reference.langchain.com/python/langchain/middleware/#langchain.agents.middleware.wrap_model_call) - 用自定义逻辑包装每次模型调用\n",
    "* [`@wrap_tool_call`](https://reference.langchain.com/python/langchain/middleware/#langchain.agents.middleware.wrap_tool_call) - 用自定义逻辑包装每次工具调用\n",
    "\n",
    "**便捷装饰器：**\n",
    "* [`@dynamic_prompt`](https://reference.langchain.com/python/langchain/middleware/#langchain.agents.middleware.dynamic_prompt) - 生成动态系统提示词\n",
    "\n",
    "**代码示例：**\n",
    "```python  theme={null}\n",
    "from langchain.agents.middleware import (\n",
    "    before_model,\n",
    "    wrap_model_call,\n",
    "    AgentState,\n",
    "    ModelRequest,\n",
    "    ModelResponse,\n",
    ")\n",
    "from langchain.agents import create_agent\n",
    "from langgraph.runtime import Runtime\n",
    "from typing import Any, Callable\n",
    "\n",
    "\n",
    "@before_model\n",
    "def log_before_model(state: AgentState, runtime: Runtime) -> dict[str, Any] | None:\n",
    "    print(f\"即将调用模型，当前消息数量: {len(state['messages'])}\")\n",
    "    return None\n",
    "\n",
    "@wrap_model_call\n",
    "def retry_model(\n",
    "    request: ModelRequest,\n",
    "    handler: Callable[[ModelRequest], ModelResponse],\n",
    ") -> ModelResponse:\n",
    "    for attempt in range(3):\n",
    "        try:\n",
    "            return handler(request)\n",
    "        except Exception as e:\n",
    "            if attempt == 2:\n",
    "                raise\n",
    "            print(f\"调用失败，正在进行第 {attempt + 1}/3 次重试，错误信息: {e}\")\n",
    "\n",
    "agent = create_agent(\n",
    "    model=\"gpt-4o\",\n",
    "    middleware=[log_before_model, retry_model],\n",
    "    tools=[...],\n",
    ")\n",
    "```\n",
    "\n",
    "**适用场景：**\n",
    "* 仅需单个钩子函数\n",
    "* 无需复杂配置\n",
    "* 快速原型开发\n",
    "\n",
    "### 基于类的中间件\n",
    "适用于包含多个钩子函数或需要复杂配置的场景，功能更强大。当你需要为同一个钩子函数同时定义同步和异步实现，或在单个中间件中组合多个钩子函数时，推荐使用类写法。\n",
    "\n",
    "**代码示例：**\n",
    "```python  theme={null}\n",
    "from langchain.agents.middleware import (\n",
    "    AgentMiddleware,\n",
    "    AgentState,\n",
    "    ModelRequest,\n",
    "    ModelResponse,\n",
    ")\n",
    "from langgraph.runtime import Runtime\n",
    "from typing import Any, Callable\n",
    "\n",
    "class LoggingMiddleware(AgentMiddleware):\n",
    "    def before_model(self, state: AgentState, runtime: Runtime) -> dict[str, Any] | None:\n",
    "        print(f\"即将调用模型，当前消息数量: {len(state['messages'])}\")\n",
    "        return None\n",
    "\n",
    "    def after_model(self, state: AgentState, runtime: Runtime) -> dict[str, Any] | None:\n",
    "        print(f\"模型返回结果: {state['messages'][-1].content}\")\n",
    "        return None\n",
    "\n",
    "agent = create_agent(\n",
    "    model=\"gpt-4o\",\n",
    "    middleware=[LoggingMiddleware()],\n",
    "    tools=[...],\n",
    ")\n",
    "```\n",
    "\n",
    "**适用场景：**\n",
    "* 需要为同一个钩子函数定义同步和异步两种实现\n",
    "* 单个中间件需包含多个钩子函数\n",
    "* 需要复杂配置（如可配置阈值、自定义模型）\n",
    "* 需要在多个项目中复用，且需在初始化时配置参数\n",
    "\n",
    "## 自定义状态模式\n",
    "中间件可以通过自定义属性扩展智能体的状态，支持以下功能：\n",
    "* **跨执行流程跟踪状态**：维护计数器、标记或其他在智能体整个生命周期中持续存在的值\n",
    "* **在钩子函数间共享数据**：将数据从`before_model`钩子函数传递到`after_model`钩子函数，或在不同中间件实例间共享数据\n",
    "* **实现横切关注点功能**：无需修改智能体核心逻辑，即可添加限流、使用量统计、用户上下文管理或审计日志等功能\n",
    "* **执行条件决策**：利用累计的状态信息，决定是否继续执行、跳转到不同节点或动态修改执行行为\n",
    "\n",
    "<Tabs>\n",
    "  <Tab title=\"装饰器写法\">\n",
    "    ```python  theme={null}\n",
    "    from langchain.agents import create_agent\n",
    "    from langchain.messages import HumanMessage\n",
    "    from langchain.agents.middleware import AgentState, before_model, after_model\n",
    "    from typing_extensions import NotRequired\n",
    "    from typing import Any\n",
    "    from langgraph.runtime import Runtime\n",
    "\n",
    "\n",
    "    class CustomState(AgentState):\n",
    "        model_call_count: NotRequired[int]\n",
    "        user_id: NotRequired[str]\n",
    "\n",
    "\n",
    "    @before_model(state_schema=CustomState, can_jump_to=[\"end\"])\n",
    "    def check_call_limit(state: CustomState, runtime: Runtime) -> dict[str, Any] | None:\n",
    "        count = state.get(\"model_call_count\", 0)\n",
    "        if count > 10:\n",
    "            return {\"jump_to\": \"end\"}\n",
    "        return None\n",
    "\n",
    "\n",
    "    @after_model(state_schema=CustomState)\n",
    "    def increment_counter(state: CustomState, runtime: Runtime) -> dict[str, Any] | None:\n",
    "        return {\"model_call_count\": state.get(\"model_call_count\", 0) + 1}\n",
    "\n",
    "\n",
    "    agent = create_agent(\n",
    "        model=\"gpt-4o\",\n",
    "        middleware=[check_call_limit, increment_counter],\n",
    "        tools=[],\n",
    "    )\n",
    "\n",
    "    # 传入自定义状态调用智能体\n",
    "    result = agent.invoke({\n",
    "        \"messages\": [HumanMessage(\"你好\")],\n",
    "        \"model_call_count\": 0,\n",
    "        \"user_id\": \"user-123\",\n",
    "    })\n",
    "    ```\n",
    "  </Tab>\n",
    "\n",
    "  <Tab title=\"类写法\">\n",
    "    ```python  theme={null}\n",
    "    from langchain.agents import create_agent\n",
    "    from langchain.messages import HumanMessage\n",
    "    from langchain.agents.middleware import AgentState, AgentMiddleware\n",
    "    from typing_extensions import NotRequired\n",
    "    from typing import Any\n",
    "\n",
    "\n",
    "    class CustomState(AgentState):\n",
    "        model_call_count: NotRequired[int]\n",
    "        user_id: NotRequired[str]\n",
    "\n",
    "\n",
    "    class CallCounterMiddleware(AgentMiddleware[CustomState]):\n",
    "        state_schema = CustomState\n",
    "\n",
    "        def before_model(self, state: CustomState, runtime) -> dict[str, Any] | None:\n",
    "            count = state.get(\"model_call_count\", 0)\n",
    "            if count > 10:\n",
    "                return {\"jump_to\": \"end\"}\n",
    "            return None\n",
    "\n",
    "        def after_model(self, state: CustomState, runtime) -> dict[str, Any] | None:\n",
    "            return {\"model_call_count\": state.get(\"model_call_count\", 0) + 1}\n",
    "\n",
    "\n",
    "    agent = create_agent(\n",
    "        model=\"gpt-4o\",\n",
    "        middleware=[CallCounterMiddleware()],\n",
    "        tools=[],\n",
    "    )\n",
    "\n",
    "    # 传入自定义状态调用智能体\n",
    "    result = agent.invoke({\n",
    "        \"messages\": [HumanMessage(\"你好\")],\n",
    "        \"model_call_count\": 0,\n",
    "        \"user_id\": \"user-123\",\n",
    "    })\n",
    "    ```\n",
    "  </Tab>\n",
    "</Tabs>\n",
    "\n",
    "## 执行顺序\n",
    "当使用多个中间件时，需了解它们的执行顺序：\n",
    "```python  theme={null}\n",
    "agent = create_agent(\n",
    "    model=\"gpt-4o\",\n",
    "    middleware=[middleware1, middleware2, middleware3],\n",
    "    tools=[...],\n",
    ")\n",
    "```\n",
    "\n",
    "<Accordion title=\"执行流程\">\n",
    "  **前置钩子函数按顺序执行：**\n",
    "  1. `middleware1.before_agent()`\n",
    "  2. `middleware2.before_agent()`\n",
    "  3. `middleware3.before_agent()`\n",
    "\n",
    "  **智能体循环启动**\n",
    "  4. `middleware1.before_model()`\n",
    "  5. `middleware2.before_model()`\n",
    "  6. `middleware3.before_model()`\n",
    "\n",
    "  **包装式钩子函数按函数调用方式嵌套执行：**\n",
    "  7. `middleware1.wrap_model_call()` → `middleware2.wrap_model_call()` → `middleware3.wrap_model_call()` → 模型调用\n",
    "\n",
    "  **后置钩子函数按逆序执行：**\n",
    "  8. `middleware3.after_model()`\n",
    "  9. `middleware2.after_model()`\n",
    "  10. `middleware1.after_model()`\n",
    "\n",
    "  **智能体循环结束**\n",
    "  11. `middleware3.after_agent()`\n",
    "  12. `middleware2.after_agent()`\n",
    "  13. `middleware1.after_agent()`\n",
    "</Accordion>\n",
    "\n",
    "**核心规则：**\n",
    "* `before_*` 系列钩子函数：按中间件列表顺序执行（从第一个到最后一个）\n",
    "* `after_*` 系列钩子函数：按中间件列表逆序执行（从最后一个到第一个）\n",
    "* `wrap_*` 系列钩子函数：按嵌套方式执行（第一个中间件包裹其他所有中间件）\n",
    "\n",
    "## 智能体跳转\n",
    "如需在中间件中提前退出执行流程，可返回一个包含`jump_to`字段的字典：\n",
    "\n",
    "**可用跳转目标：**\n",
    "* `'end'`：跳转到智能体执行流程的末尾（或第一个`after_agent`钩子函数）\n",
    "* `'tools'`：跳转到工具节点\n",
    "* `'model'`：跳转到模型节点（或第一个`before_model`钩子函数）\n",
    "\n",
    "<Tabs>\n",
    "  <Tab title=\"装饰器写法\">\n",
    "    ```python  theme={null}\n",
    "    from langchain.agents.middleware import after_model, hook_config, AgentState\n",
    "    from langchain.messages import AIMessage\n",
    "    from langgraph.runtime import Runtime\n",
    "    from typing import Any\n",
    "\n",
    "\n",
    "    @after_model\n",
    "    @hook_config(can_jump_to=[\"end\"])\n",
    "    def check_for_blocked(state: AgentState, runtime: Runtime) -> dict[str, Any] | None:\n",
    "        last_message = state[\"messages\"][-1]\n",
    "        if \"BLOCKED\" in last_message.content:\n",
    "            return {\n",
    "                \"messages\": [AIMessage(\"我无法响应该请求。\")],\n",
    "                \"jump_to\": \"end\"\n",
    "            }\n",
    "        return None\n",
    "    ```\n",
    "  </Tab>\n",
    "\n",
    "  <Tab title=\"类写法\">\n",
    "    ```python  theme={null}\n",
    "    from langchain.agents.middleware import AgentMiddleware, hook_config, AgentState\n",
    "    from langchain.messages import AIMessage\n",
    "    from langgraph.runtime import Runtime\n",
    "    from typing import Any\n",
    "\n",
    "    class BlockedContentMiddleware(AgentMiddleware):\n",
    "        @hook_config(can_jump_to=[\"end\"])\n",
    "        def after_model(self, state: AgentState, runtime: Runtime) -> dict[str, Any] | None:\n",
    "            last_message = state[\"messages\"][-1]\n",
    "            if \"BLOCKED\" in last_message.content:\n",
    "                return {\n",
    "                    \"messages\": [AIMessage(\"我无法响应该请求。\")],\n",
    "                    \"jump_to\": \"end\"\n",
    "                }\n",
    "            return None\n",
    "    ```\n",
    "  </Tab>\n",
    "</Tabs>\n",
    "\n",
    "## 最佳实践\n",
    "1.  保持中间件功能单一性——每个中间件专注实现一个功能\n",
    "2.  优雅处理异常——避免因中间件异常导致智能体崩溃\n",
    "3.  **选择合适的钩子函数类型**\n",
    "    * 节点式钩子函数：适用于日志记录、参数校验等顺序执行逻辑\n",
    "    * 包装式钩子函数：适用于重试、降级、缓存等流程控制场景\n",
    "4.  清晰标注所有自定义状态属性\n",
    "5.  集成到智能体前，先对中间件进行独立单元测试\n",
    "6.  考虑执行顺序——将核心中间件放在列表首位\n",
    "7.  优先使用内置中间件\n",
    "\n",
    "## 实战案例\n",
    "\n",
    "### 动态模型选择\n",
    "\n",
    "<Tabs>\n",
    "  <Tab title=\"装饰器写法\">\n",
    "    ```python  theme={null}\n",
    "    from langchain.agents.middleware import wrap_model_call, ModelRequest, ModelResponse\n",
    "    from langchain.chat_models import init_chat_model\n",
    "    from typing import Callable\n",
    "\n",
    "\n",
    "    complex_model = init_chat_model(\"gpt-4o\")\n",
    "    simple_model = init_chat_model(\"gpt-4o-mini\")\n",
    "\n",
    "    @wrap_model_call\n",
    "    def dynamic_model(\n",
    "        request: ModelRequest,\n",
    "        handler: Callable[[ModelRequest], ModelResponse],\n",
    "    ) -> ModelResponse:\n",
    "        # 根据对话长度选择不同模型\n",
    "        if len(request.messages) > 10:\n",
    "            model = complex_model\n",
    "        else:\n",
    "            model = simple_model\n",
    "        return handler(request.override(model=model))\n",
    "    ```\n",
    "  </Tab>\n",
    "\n",
    "  <Tab title=\"类写法\">\n",
    "    ```python  theme={null}\n",
    "    from langchain.agents.middleware import AgentMiddleware, ModelRequest, ModelResponse\n",
    "    from langchain.chat_models import init_chat_model\n",
    "    from typing import Callable\n",
    "\n",
    "    complex_model = init_chat_model(\"gpt-4o\")\n",
    "    simple_model = init_chat_model(\"gpt-4o-mini\")\n",
    "\n",
    "    class DynamicModelMiddleware(AgentMiddleware):\n",
    "        def wrap_model_call(\n",
    "            self,\n",
    "            request: ModelRequest,\n",
    "            handler: Callable[[ModelRequest], ModelResponse],\n",
    "        ) -> ModelResponse:\n",
    "            # 根据对话长度选择不同模型\n",
    "            if len(request.messages) > 10:\n",
    "                model = complex_model\n",
    "            else:\n",
    "                model = simple_model\n",
    "            return handler(request.override(model=model))\n",
    "    ```\n",
    "  </Tab>\n",
    "</Tabs>\n",
    "\n",
    "### 工具调用监控\n",
    "\n",
    "<Tabs>\n",
    "  <Tab title=\"装饰器写法\">\n",
    "    ```python  theme={null}\n",
    "    from langchain.agents.middleware import wrap_tool_call\n",
    "    from langchain.tools.tool_node import ToolCallRequest\n",
    "    from langchain.messages import ToolMessage\n",
    "    from langgraph.types import Command\n",
    "    from typing import Callable\n",
    "\n",
    "\n",
    "    @wrap_tool_call\n",
    "    def monitor_tool(\n",
    "        request: ToolCallRequest,\n",
    "        handler: Callable[[ToolCallRequest], ToolMessage | Command],\n",
    "    ) -> ToolMessage | Command:\n",
    "        print(f\"正在执行工具: {request.tool_call['name']}\")\n",
    "        print(f\"工具参数: {request.tool_call['args']}\")\n",
    "        try:\n",
    "            result = handler(request)\n",
    "            print(f\"工具执行成功\")\n",
    "            return result\n",
    "        except Exception as e:\n",
    "            print(f\"工具执行失败: {e}\")\n",
    "            raise\n",
    "    ```\n",
    "  </Tab>\n",
    "\n",
    "  <Tab title=\"类写法\">\n",
    "    ```python  theme={null}\n",
    "    from langchain.tools.tool_node import ToolCallRequest\n",
    "    from langchain.agents.middleware import AgentMiddleware\n",
    "    from langchain.messages import ToolMessage\n",
    "    from langgraph.types import Command\n",
    "    from typing import Callable\n",
    "\n",
    "    class ToolMonitoringMiddleware(AgentMiddleware):\n",
    "        def wrap_tool_call(\n",
    "            self,\n",
    "            request: ToolCallRequest,\n",
    "            handler: Callable[[ToolCallRequest], ToolMessage | Command],\n",
    "        ) -> ToolMessage | Command:\n",
    "            print(f\"正在执行工具: {request.tool_call['name']}\")\n",
    "            print(f\"工具参数: {request.tool_call['args']}\")\n",
    "            try:\n",
    "                result = handler(request)\n",
    "                print(f\"工具执行成功\")\n",
    "                return result\n",
    "            except Exception as e:\n",
    "                print(f\"工具执行失败: {e}\")\n",
    "                raise\n",
    "    ```\n",
    "  </Tab>\n",
    "</Tabs>\n",
    "\n",
    "### 动态工具选择\n",
    "在运行时选择相关工具，提升智能体执行性能和准确性。\n",
    "\n",
    "**优势：**\n",
    "* **精简提示词**：仅暴露相关工具，降低提示词复杂度\n",
    "* **提高准确性**：模型从更少的工具选项中选择，决策更精准\n",
    "* **权限控制**：基于用户权限动态过滤工具\n",
    "\n",
    "<Tabs>\n",
    "  <Tab title=\"装饰器写法\">\n",
    "    ```python  theme={null}\n",
    "    from langchain.agents import create_agent\n",
    "    from langchain.agents.middleware import wrap_model_call, ModelRequest, ModelResponse\n",
    "    from typing import Callable\n",
    "\n",
    "\n",
    "    @wrap_model_call\n",
    "    def select_tools(\n",
    "        request: ModelRequest,\n",
    "        handler: Callable[[ModelRequest], ModelResponse],\n",
    "    ) -> ModelResponse:\n",
    "        \"\"\"基于状态/上下文选择相关工具的中间件\"\"\"\n",
    "        # 根据状态和上下文选择少量相关工具\n",
    "        relevant_tools = select_relevant_tools(request.state, request.runtime)\n",
    "        return handler(request.override(tools=relevant_tools))\n",
    "\n",
    "    agent = create_agent(\n",
    "        model=\"gpt-4o\",\n",
    "        tools=all_tools,  # 需提前注册所有可用工具\n",
    "        middleware=[select_tools],\n",
    "    )\n",
    "    ```\n",
    "  </Tab>\n",
    "\n",
    "  <Tab title=\"类写法\">\n",
    "    ```python  theme={null}\n",
    "    from langchain.agents import create_agent\n",
    "    from langchain.agents.middleware import AgentMiddleware, ModelRequest, ModelResponse\n",
    "    from typing import Callable\n",
    "\n",
    "\n",
    "    class ToolSelectorMiddleware(AgentMiddleware):\n",
    "        def wrap_model_call(\n",
    "            self,\n",
    "            request: ModelRequest,\n",
    "            handler: Callable[[ModelRequest], ModelResponse],\n",
    "        ) -> ModelResponse:\n",
    "            \"\"\"基于状态/上下文选择相关工具的中间件\"\"\"\n",
    "            # 根据状态和上下文选择少量相关工具\n",
    "            relevant_tools = select_relevant_tools(request.state, request.runtime)\n",
    "            return handler(request.override(tools=relevant_tools))\n",
    "\n",
    "    agent = create_agent(\n",
    "        model=\"gpt-4o\",\n",
    "        tools=all_tools,  # 需提前注册所有可用工具\n",
    "        middleware=[ToolSelectorMiddleware()],\n",
    "    )\n",
    "    ```\n",
    "  </Tab>\n",
    "</Tabs>\n",
    "\n",
    "### 系统消息处理\n",
    "可通过`ModelRequest`对象的`system_message`字段在中间件中修改系统消息。无论智能体初始化时传入的是字符串类型的`system_prompt`，`system_message`字段始终存储的是一个 [`SystemMessage`](https://reference.langchain.com/python/langchain/messages/#langchain.messages.SystemMessage) 对象。\n",
    "\n",
    "**案例：为系统消息添加上下文信息**\n",
    "\n",
    "<Tabs>\n",
    "  <Tab title=\"装饰器写法\">\n",
    "    ```python  theme={null}\n",
    "    from langchain.agents.middleware import wrap_model_call, ModelRequest, ModelResponse\n",
    "    from langchain.messages import SystemMessage\n",
    "    from typing import Callable\n",
    "\n",
    "\n",
    "    @wrap_model_call\n",
    "    def add_context(\n",
    "        request: ModelRequest,\n",
    "        handler: Callable[[ModelRequest], ModelResponse],\n",
    "    ) -> ModelResponse:\n",
    "        # 操作内容块列表\n",
    "        new_content = list(request.system_message.content_blocks) + [\n",
    "            {\"type\": \"text\", \"text\": \"补充上下文信息。\"}\n",
    "        ]\n",
    "        new_system_message = SystemMessage(content=new_content)\n",
    "        return handler(request.override(system_message=new_system_message))\n",
    "    ```\n",
    "  </Tab>\n",
    "\n",
    "  <Tab title=\"类写法\">\n",
    "    ```python  theme={null}\n",
    "    from langchain.agents.middleware import AgentMiddleware, ModelRequest, ModelResponse\n",
    "    from langchain.messages import SystemMessage\n",
    "    from typing import Callable\n",
    "\n",
    "\n",
    "    class ContextMiddleware(AgentMiddleware):\n",
    "        def wrap_model_call(\n",
    "            self,\n",
    "            request: ModelRequest,\n",
    "            handler: Callable[[ModelRequest], ModelResponse],\n",
    "        ) -> ModelResponse:\n",
    "            # 操作内容块列表\n",
    "            new_content = list(request.system_message.content_blocks) + [\n",
    "                {\"type\": \"text\", \"text\": \"补充上下文信息。\"}\n",
    "            ]\n",
    "            new_system_message = SystemMessage(content=new_content)\n",
    "            return handler(request.override(system_message=new_system_message))\n",
    "    ```\n",
    "  </Tab>\n",
    "</Tabs>\n",
    "\n",
    "**案例：缓存控制（适用于Anthropic模型）**\n",
    "使用Anthropic模型时，可通过带缓存控制指令的结构化内容块，对大型系统提示词进行缓存：\n",
    "\n",
    "<Tabs>\n",
    "  <Tab title=\"装饰器写法\">\n",
    "    ```python  theme={null}\n",
    "    from langchain.agents.middleware import wrap_model_call, ModelRequest, ModelResponse\n",
    "    from langchain.messages import SystemMessage\n",
    "    from typing import Callable\n",
    "\n",
    "\n",
    "    @wrap_model_call\n",
    "    def add_cached_context(\n",
    "        request: ModelRequest,\n",
    "        handler: Callable[[ModelRequest], ModelResponse],\n",
    "    ) -> ModelResponse:\n",
    "        # 操作内容块列表\n",
    "        new_content = list(request.system_message.content_blocks) + [\n",
    "            {\n",
    "                \"type\": \"text\",\n",
    "                \"text\": \"以下是待分析的大型文档内容:\\n\\n<document>...</document>\",\n",
    "                # 此前的内容将被缓存\n",
    "                \"cache_control\": {\"type\": \"ephemeral\"}\n",
    "            }\n",
    "        ]\n",
    "\n",
    "        new_system_message = SystemMessage(content=new_content)\n",
    "        return handler(request.override(system_message=new_system_message))\n",
    "    ```\n",
    "  </Tab>\n",
    "\n",
    "  <Tab title=\"类写法\">\n",
    "    ```python  theme={null}\n",
    "    from langchain.agents.middleware import AgentMiddleware, ModelRequest, ModelResponse\n",
    "    from langchain.messages import SystemMessage\n",
    "    from typing import Callable\n",
    "\n",
    "\n",
    "    class CachedContextMiddleware(AgentMiddleware):\n",
    "        def wrap_model_call(\n",
    "            self,\n",
    "            request: ModelRequest,\n",
    "            handler: Callable[[ModelRequest], ModelResponse],\n",
    "        ) -> ModelResponse:\n",
    "            # 操作内容块列表\n",
    "            new_content = list(request.system_message.content_blocks) + [\n",
    "                {\n",
    "                    \"type\": \"text\",\n",
    "                    \"text\": \"以下是待分析的大型文档内容:\\n\\n<document>...</document>\",\n",
    "                    \"cache_control\": {\"type\": \"ephemeral\"}  # 该部分内容将被缓存\n",
    "                }\n",
    "            ]\n",
    "\n",
    "            new_system_message = SystemMessage(content=new_content)\n",
    "            return handler(request.override(system_message=new_system_message))\n",
    "    ```\n",
    "  </Tab>\n",
    "</Tabs>\n",
    "\n",
    "**注意事项：**\n",
    "* 无论智能体初始化时传入的是字符串类型的`system_prompt`，`ModelRequest.system_message`始终是一个 [`SystemMessage`](https://reference.langchain.com/python/langchain/messages/#langchain.messages.SystemMessage) 对象\n",
    "* 可通过`SystemMessage.content_blocks`属性，以内容块列表的形式访问系统消息内容，无论原始内容是字符串还是列表格式\n",
    "* 修改系统消息时，建议使用`content_blocks`属性并追加新的内容块，以保留原有内容结构\n",
    "* 对于缓存控制等高级场景，可直接将 [`SystemMessage`](https://reference.langchain.com/python/langchain/messages/#langchain.messages.SystemMessage) 对象传入`create_agent`函数的`system_prompt`参数\n",
    "\n",
    "## 拓展资源\n",
    "* [中间件API参考文档](https://reference.langchain.com/python/langchain/middleware/)\n",
    "* [内置中间件列表](/oss/python/langchain/middleware/built-in)\n",
    "* [智能体测试指南](/oss/python/langchain/test)\n",
    "\n",
    "***\n",
    "\n",
    "<Callout icon=\"pen-to-square\" iconType=\"regular\">\n",
    "  [在GitHub上编辑本页内容](https://github.com/langchain-ai/docs/edit/main/src/oss/langchain/middleware/custom.mdx)\n",
    "</Callout>\n",
    "\n",
    "<Tip icon=\"terminal\" iconType=\"regular\">\n",
    "  [通过MCP将这些文档接入Claude、VSCode等工具](/use-these-docs)，获取实时解答\n",
    "</Tip>\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "> 如需查看本文档的导航目录及其他页面，可获取llms.txt文件：https://docs.langchain.com/llms.txt"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
