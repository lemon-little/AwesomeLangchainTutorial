{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b67f03e1",
   "metadata": {},
   "source": [
    "## MCP 工具调用"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c396ca19",
   "metadata": {},
   "source": [
    "https://github.com/langchain-ai/langchain-mcp-adapters  \n",
    "pip install langchain-mcp-adapters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0942dad",
   "metadata": {},
   "source": [
    "# Quickstart\n",
    "## Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b42a9fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create server parameters for stdio connection\n",
    "from mcp import ClientSession, StdioServerParameters\n",
    "from mcp.client.stdio import stdio_client\n",
    "\n",
    "from langchain_mcp_adapters.tools import load_mcp_tools\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# 配置mcp服务参数，Python代码函数\n",
    "server_params = StdioServerParameters(\n",
    "    command=\"python\",\n",
    "    # Make sure to update to the full absolute path to your math_server.py file\n",
    "    args=[\"/Users/lzc/TNTprojectZ/LangChainStudy/math_server.py\"],\n",
    ")\n",
    "\n",
    "async with stdio_client(server_params) as (read, write):\n",
    "    async with ClientSession(read, write) as session:\n",
    "        # Initialize the connection\n",
    "        await session.initialize()\n",
    "\n",
    "        # Get tools\n",
    "        tools = await load_mcp_tools(session)\n",
    "\n",
    "        # Create and run the agent\n",
    "        llm = ChatOpenAI(\n",
    "            model=\"Qwen/Qwen3-8B\",\n",
    "            # model=\"Qwen/Qwen3-30B-A3B-Instruct-2507\",\n",
    "            api_key=\"sk-jvjyawqpodlkxlywatvemcdykkrbvthhjyjyapyvtnifwlbl\",\n",
    "            base_url=\"https://api.siliconflow.cn/v1/\",\n",
    "        )\n",
    "        agent = create_react_agent(llm, tools)\n",
    "        agent_response = await agent.ainvoke({\"messages\": \"what's (3 + 5) x 12?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cc99b180",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content=\"what's (3 + 5) x 12?\", additional_kwargs={}, response_metadata={}, id='ec97392c-d101-4cb8-9ab0-351b2521efcb'),\n",
       "  AIMessage(content='\\n\\n', additional_kwargs={'tool_calls': [{'id': '0198dfb1b9edf9f0b894133ac8072227', 'function': {'arguments': ' {\"a\": 3, \"b\": 5}', 'name': 'add'}, 'type': 'function', 'index': 0}, {'id': '0198dfb1bc1ca9c2dd22bffde46de48e', 'function': {'arguments': ' {\"a\": 8, \"b\": 12}', 'name': 'multiply'}, 'type': 'function', 'index': 1}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 535, 'prompt_tokens': 239, 'total_tokens': 774, 'completion_tokens_details': {'accepted_prediction_tokens': None, 'audio_tokens': None, 'reasoning_tokens': 507, 'rejected_prediction_tokens': None}, 'prompt_tokens_details': None}, 'model_name': 'Qwen/Qwen3-8B', 'system_fingerprint': '', 'id': '0198dfb172b64ff27c340c41d646b53f', 'service_tier': None, 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--7e448b5b-76d8-44c8-9a41-ca236228e958-0', tool_calls=[{'name': 'add', 'args': {'a': 3, 'b': 5}, 'id': '0198dfb1b9edf9f0b894133ac8072227', 'type': 'tool_call'}, {'name': 'multiply', 'args': {'a': 8, 'b': 12}, 'id': '0198dfb1bc1ca9c2dd22bffde46de48e', 'type': 'tool_call'}], usage_metadata={'input_tokens': 239, 'output_tokens': 535, 'total_tokens': 774, 'input_token_details': {}, 'output_token_details': {'reasoning': 507}}),\n",
       "  ToolMessage(content='8', name='add', id='672ddf6f-5227-4df2-8bec-7d370f3b2ac9', tool_call_id='0198dfb1b9edf9f0b894133ac8072227'),\n",
       "  ToolMessage(content='96', name='multiply', id='a4f1bc9c-52dc-42d9-8c9e-072f17771d8f', tool_call_id='0198dfb1bc1ca9c2dd22bffde46de48e'),\n",
       "  AIMessage(content='\\n\\nThe result of (3 + 5) x 12 is 96. \\n\\nFirst, we add 3 and 5 to get 8, then multiply 8 by 12 to obtain the final answer.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 181, 'prompt_tokens': 311, 'total_tokens': 492, 'completion_tokens_details': {'accepted_prediction_tokens': None, 'audio_tokens': None, 'reasoning_tokens': 133, 'rejected_prediction_tokens': None}, 'prompt_tokens_details': None}, 'model_name': 'Qwen/Qwen3-8B', 'system_fingerprint': '', 'id': '0198dfb1bea8509a1dd304c38f819a12', 'service_tier': None, 'finish_reason': 'stop', 'logprobs': None}, id='run--79b89c77-5692-442c-bd0b-3010e4e887b1-0', usage_metadata={'input_tokens': 311, 'output_tokens': 181, 'total_tokens': 492, 'input_token_details': {}, 'output_token_details': {'reasoning': 133}})]}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce1a65af",
   "metadata": {},
   "source": [
    "# Multiple MCP Servers\n",
    "## Server\n",
    "### math_server.py\n",
    "### weather_server.py\n",
    "## Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b91ebe71",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_mcp_adapters.client import MultiServerMCPClient\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "\n",
    "client = MultiServerMCPClient(\n",
    "    {\n",
    "        \"math\": {\n",
    "            \"command\": \"python\",\n",
    "            # Make sure to update to the full absolute path to your math_server.py file\n",
    "            \"args\": [\"/Users/lzc/TNTprojectZ/LangChainStudy/math_server.py\"],\n",
    "            \"transport\": \"stdio\",\n",
    "        },\n",
    "        \"weather\": {\n",
    "            # 命令行运行python weather_server.py\n",
    "            # Make sure you start your weather server on port 8000\n",
    "            \"url\": \"http://localhost:8000/mcp/\",\n",
    "            \"transport\": \"streamable_http\",\n",
    "        }\n",
    "    }\n",
    ")\n",
    "tools = await client.get_tools()\n",
    "llm = ChatOpenAI(\n",
    "        model=\"Qwen/Qwen3-8B\",\n",
    "        # model=\"Qwen/Qwen3-30B-A3B-Instruct-2507\",\n",
    "        api_key=\"sk-jvjyawqpodlkxlywatvemcdykkrbvthhjyjyapyvtnifwlbl\",\n",
    "        base_url=\"https://api.siliconflow.cn/v1/\",\n",
    "    )\n",
    "agent = create_react_agent(llm, tools)\n",
    "math_response = await agent.ainvoke({\"messages\": \"what's (3 + 5) x 12?\"})\n",
    "weather_response = await agent.ainvoke({\"messages\": \"what is the weather in nyc?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "667900ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content=\"what's (3 + 5) x 12?\", additional_kwargs={}, response_metadata={}, id='38325d60-a373-48fb-acba-454aa8a128e3'),\n",
       "  AIMessage(content='\\n\\n', additional_kwargs={'tool_calls': [{'id': '0198e04d3b01768d8d9310d7860d9ebf', 'function': {'arguments': ' {\"a\": 3, \"b\": 5}', 'name': 'add'}, 'type': 'function', 'index': 0}, {'id': '0198e04d3d12351ff0456ed52e41dfd9', 'function': {'arguments': ' {\"a\": 8, \"b\": 12}', 'name': 'multiply'}, 'type': 'function', 'index': 1}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 276, 'prompt_tokens': 297, 'total_tokens': 573, 'completion_tokens_details': {'accepted_prediction_tokens': None, 'audio_tokens': None, 'reasoning_tokens': 248, 'rejected_prediction_tokens': None}, 'prompt_tokens_details': None}, 'model_name': 'Qwen/Qwen3-8B', 'system_fingerprint': '', 'id': '0198e04d23d0929317325df679648a65', 'service_tier': None, 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--3fdfa052-eb3c-4849-a111-1cf210fc410f-0', tool_calls=[{'name': 'add', 'args': {'a': 3, 'b': 5}, 'id': '0198e04d3b01768d8d9310d7860d9ebf', 'type': 'tool_call'}, {'name': 'multiply', 'args': {'a': 8, 'b': 12}, 'id': '0198e04d3d12351ff0456ed52e41dfd9', 'type': 'tool_call'}], usage_metadata={'input_tokens': 297, 'output_tokens': 276, 'total_tokens': 573, 'input_token_details': {}, 'output_token_details': {'reasoning': 248}}),\n",
       "  ToolMessage(content='8', name='add', id='241817ac-2dc4-4194-8d93-49222954562e', tool_call_id='0198e04d3b01768d8d9310d7860d9ebf'),\n",
       "  ToolMessage(content='96', name='multiply', id='ef5805e3-5609-4e0a-9aa2-28786dc7f824', tool_call_id='0198e04d3d12351ff0456ed52e41dfd9'),\n",
       "  AIMessage(content='\\n\\nThe value of (3 + 5) x 12 is calculated as follows:\\n\\n1. First, add 3 and 5:  \\n   $ 3 + 5 = 8 $\\n\\n2. Then, multiply the result by 12:  \\n   $ 8 \\\\times 12 = 96 $\\n\\n**Final Answer:** 96', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 319, 'prompt_tokens': 369, 'total_tokens': 688, 'completion_tokens_details': {'accepted_prediction_tokens': None, 'audio_tokens': None, 'reasoning_tokens': 243, 'rejected_prediction_tokens': None}, 'prompt_tokens_details': None}, 'model_name': 'Qwen/Qwen3-8B', 'system_fingerprint': '', 'id': '0198e04d40c122cff1c6bfd4ee657203', 'service_tier': None, 'finish_reason': 'stop', 'logprobs': None}, id='run--84900f12-3fdc-4fdd-8288-d84d364587fa-0', usage_metadata={'input_tokens': 369, 'output_tokens': 319, 'total_tokens': 688, 'input_token_details': {}, 'output_token_details': {'reasoning': 243}})]}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "math_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eab8d2e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='what is the weather in nyc?', additional_kwargs={}, response_metadata={}, id='b2ce4d72-39a6-4300-9c30-b1280a53cb37'),\n",
       "  AIMessage(content='\\n\\n', additional_kwargs={'tool_calls': [{'id': '0198e04d8866e3a9d56aee79d15d8924', 'function': {'arguments': ' {\"location\": \"nyc\"}', 'name': 'get_weather'}, 'type': 'function', 'index': 0}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 99, 'prompt_tokens': 292, 'total_tokens': 391, 'completion_tokens_details': {'accepted_prediction_tokens': None, 'audio_tokens': None, 'reasoning_tokens': 90, 'rejected_prediction_tokens': None}, 'prompt_tokens_details': None}, 'model_name': 'Qwen/Qwen3-8B', 'system_fingerprint': '', 'id': '0198e04d75ec4b046f60cec8c817ccf4', 'service_tier': None, 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--967b3e11-00ca-4227-88bc-c0c8ff199d4b-0', tool_calls=[{'name': 'get_weather', 'args': {'location': 'nyc'}, 'id': '0198e04d8866e3a9d56aee79d15d8924', 'type': 'tool_call'}], usage_metadata={'input_tokens': 292, 'output_tokens': 99, 'total_tokens': 391, 'input_token_details': {}, 'output_token_details': {'reasoning': 90}}),\n",
       "  ToolMessage(content=\"It's always sunny in New York\", name='get_weather', id='d347e350-a060-4e9e-a887-5c6a1712db05', tool_call_id='0198e04d8866e3a9d56aee79d15d8924'),\n",
       "  AIMessage(content='\\n\\nThe weather in New York is sunny. ☀️', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 576, 'prompt_tokens': 333, 'total_tokens': 909, 'completion_tokens_details': {'accepted_prediction_tokens': None, 'audio_tokens': None, 'reasoning_tokens': 564, 'rejected_prediction_tokens': None}, 'prompt_tokens_details': None}, 'model_name': 'Qwen/Qwen3-8B', 'system_fingerprint': '', 'id': '0198e04d8bda75747d3d5d5858bde4e5', 'service_tier': None, 'finish_reason': 'stop', 'logprobs': None}, id='run--b3adcebe-6b23-4e66-a215-2e066e27bbdd-0', usage_metadata={'input_tokens': 333, 'output_tokens': 576, 'total_tokens': 909, 'input_token_details': {}, 'output_token_details': {'reasoning': 564}})]}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather_response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcd54641",
   "metadata": {},
   "source": [
    "# Streamable HTTP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "216effd3",
   "metadata": {},
   "source": [
    "### To use it with Python MCP SDK streamablehttp_client:\n",
    "```\n",
    "cd examples/servers/streamable-http-stateless/  \n",
    "uv run mcp-simple-streamablehttp-stateless --port 3000\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6c5d136e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'messages': [HumanMessage(content=\"what's (3 + 5) x 12?\", additional_kwargs={}, response_metadata={}, id='61a03684-a05a-42e9-8c86-b1fdf9d1dc5d'), AIMessage(content='\\n\\n', additional_kwargs={'tool_calls': [{'id': '0198e07018033106d3f41fc2d483c3a5', 'function': {'arguments': ' {\"a\": 3, \"b\": 5}', 'name': 'add'}, 'type': 'function', 'index': 0}, {'id': '0198e0701b82b448d78eb96a1eb199d1', 'function': {'arguments': ' {\"a\": 8, \"b\": 12}', 'name': 'multiply'}, 'type': 'function', 'index': 1}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 433, 'prompt_tokens': 344, 'total_tokens': 777, 'completion_tokens_details': {'accepted_prediction_tokens': None, 'audio_tokens': None, 'reasoning_tokens': 405, 'rejected_prediction_tokens': None}, 'prompt_tokens_details': None}, 'model_name': 'Qwen/Qwen3-8B', 'system_fingerprint': '', 'id': '0198e06fde713c011837cbe398d568e0', 'service_tier': None, 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--05516e1d-091a-45a8-8f3f-2711abfea647-0', tool_calls=[{'name': 'add', 'args': {'a': 3, 'b': 5}, 'id': '0198e07018033106d3f41fc2d483c3a5', 'type': 'tool_call'}, {'name': 'multiply', 'args': {'a': 8, 'b': 12}, 'id': '0198e0701b82b448d78eb96a1eb199d1', 'type': 'tool_call'}], usage_metadata={'input_tokens': 344, 'output_tokens': 433, 'total_tokens': 777, 'input_token_details': {}, 'output_token_details': {'reasoning': 405}}), ToolMessage(content='8', name='add', id='702f0e4a-8dbb-4ec6-a2cb-19d4033a3844', tool_call_id='0198e07018033106d3f41fc2d483c3a5'), ToolMessage(content='96', name='multiply', id='3e06b7bc-62c7-4d45-b747-dbc4c3bff75f', tool_call_id='0198e0701b82b448d78eb96a1eb199d1'), AIMessage(content='\\n\\nThe result of (3 + 5) x 12 is 96. First, we add 3 and 5 to get 8, then multiply 8 by 12 to obtain the final answer.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 199, 'prompt_tokens': 416, 'total_tokens': 615, 'completion_tokens_details': {'accepted_prediction_tokens': None, 'audio_tokens': None, 'reasoning_tokens': 152, 'rejected_prediction_tokens': None}, 'prompt_tokens_details': None}, 'model_name': 'Qwen/Qwen3-8B', 'system_fingerprint': '', 'id': '0198e0701f1052154dfdf349790d9938', 'service_tier': None, 'finish_reason': 'stop', 'logprobs': None}, id='run--cee27098-59c1-40b7-a1c1-eb8630ff619f-0', usage_metadata={'input_tokens': 416, 'output_tokens': 199, 'total_tokens': 615, 'input_token_details': {}, 'output_token_details': {'reasoning': 152}})]}\n",
      "{'messages': [HumanMessage(content='what is the weather in New York?', additional_kwargs={}, response_metadata={}, id='1f1e351f-e6e8-4a90-ba65-732a748ae636'), AIMessage(content='\\n\\n', additional_kwargs={'tool_calls': [{'id': '0198e0705ad5b88ca15cd1d60f3444b1', 'function': {'arguments': ' {\"location\": \"New York\"}', 'name': 'get_weather'}, 'type': 'function', 'index': 0}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 95, 'prompt_tokens': 339, 'total_tokens': 434, 'completion_tokens_details': {'accepted_prediction_tokens': None, 'audio_tokens': None, 'reasoning_tokens': 86, 'rejected_prediction_tokens': None}, 'prompt_tokens_details': None}, 'model_name': 'Qwen/Qwen3-8B', 'system_fingerprint': '', 'id': '0198e07048b796ddd4ffbc68d3088b63', 'service_tier': None, 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--d09ee855-f5bf-436a-8751-7b4ff29b76fa-0', tool_calls=[{'name': 'get_weather', 'args': {'location': 'New York'}, 'id': '0198e0705ad5b88ca15cd1d60f3444b1', 'type': 'tool_call'}], usage_metadata={'input_tokens': 339, 'output_tokens': 95, 'total_tokens': 434, 'input_token_details': {}, 'output_token_details': {'reasoning': 86}}), ToolMessage(content=\"It's always sunny in New York.\", name='get_weather', id='64d22bd6-e39e-40c2-8fcb-04bc288a053e', tool_call_id='0198e0705ad5b88ca15cd1d60f3444b1'), AIMessage(content='\\n\\nThe weather in New York is sunny.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 223, 'prompt_tokens': 380, 'total_tokens': 603, 'completion_tokens_details': {'accepted_prediction_tokens': None, 'audio_tokens': None, 'reasoning_tokens': 214, 'rejected_prediction_tokens': None}, 'prompt_tokens_details': None}, 'model_name': 'Qwen/Qwen3-8B', 'system_fingerprint': '', 'id': '0198e0705dc5ff0a11313fcde69f7c5e', 'service_tier': None, 'finish_reason': 'stop', 'logprobs': None}, id='run--6975e4f2-cebb-41e1-8254-123e6dfbc51c-0', usage_metadata={'input_tokens': 380, 'output_tokens': 223, 'total_tokens': 603, 'input_token_details': {}, 'output_token_details': {'reasoning': 214}})]}\n"
     ]
    }
   ],
   "source": [
    "# Use server from examples/servers/streamable-http-stateless/\n",
    "\n",
    "from mcp import ClientSession\n",
    "from mcp.client.streamable_http import streamablehttp_client\n",
    "\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "from langchain_mcp_adapters.tools import load_mcp_tools\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# cd examples/servers/streamable-http-stateless/  \n",
    "# uv run mcp-simple-streamablehttp-stateless --port 3000\n",
    "# 启动mcp服务器，地址：http://0.0.0.0:3000\n",
    "async with streamablehttp_client(\"http://localhost:3000/mcp/\") as (read, write, _):\n",
    "    async with ClientSession(read, write) as session:\n",
    "        # Initialize the connection\n",
    "        await session.initialize()\n",
    "\n",
    "        # Get tools\n",
    "        tools = await load_mcp_tools(session)\n",
    "        llm = ChatOpenAI(\n",
    "            model=\"Qwen/Qwen3-8B\",\n",
    "            # model=\"Qwen/Qwen3-30B-A3B-Instruct-2507\",\n",
    "            api_key=\"sk-jvjyawqpodlkxlywatvemcdykkrbvthhjyjyapyvtnifwlbl\",\n",
    "            base_url=\"https://api.siliconflow.cn/v1/\",\n",
    "        )\n",
    "        agent = create_react_agent(llm, tools)\n",
    "        math_response = await agent.ainvoke({\"messages\": \"what's (3 + 5) x 12?\"})\n",
    "        weather_response = await agent.ainvoke({\"messages\": \"what is the weather in New York?\"})\n",
    "        print(math_response)\n",
    "        print(weather_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c23a0352",
   "metadata": {},
   "source": [
    "{'messages': [HumanMessage(content='what is the weather in New York?', additional_kwargs={}, response_metadata={}, id='1f1e351f-e6e8-4a90-ba65-732a748ae636'), AIMessage(content='\\n\\n', additional_kwargs={'tool_calls': [{'id': '0198e0705ad5b88ca15cd1d60f3444b1', 'function': {'arguments': ' {\"location\": \"New York\"}', 'name': 'get_weather'}, 'type': 'function', 'index': 0}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 95, 'prompt_tokens': 339, 'total_tokens': 434, 'completion_tokens_details': {'accepted_prediction_tokens': None, 'audio_tokens': None, 'reasoning_tokens': 86, 'rejected_prediction_tokens': None}, 'prompt_tokens_details': None}, 'model_name': 'Qwen/Qwen3-8B', 'system_fingerprint': '', 'id': '0198e07048b796ddd4ffbc68d3088b63', 'service_tier': None, 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--d09ee855-f5bf-436a-8751-7b4ff29b76fa-0', tool_calls=[{'name': 'get_weather', 'args': {'location': 'New York'}, 'id': '0198e0705ad5b88ca15cd1d60f3444b1', 'type': 'tool_call'}], usage_metadata={'input_tokens': 339, 'output_tokens': 95, 'total_tokens': 434, 'input_token_details': {}, 'output_token_details': {'reasoning': 86}}), ToolMessage(content=\"It's always sunny in New York.\", name='get_weather', id='64d22bd6-e39e-40c2-8fcb-04bc288a053e', tool_call_id='0198e0705ad5b88ca15cd1d60f3444b1'), AIMessage(content='\\n\\nThe weather in New York is sunny.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 223, 'prompt_tokens': 380, 'total_tokens': 603, 'completion_tokens_details': {'accepted_prediction_tokens': None, 'audio_tokens': None, 'reasoning_tokens': 214, 'rejected_prediction_tokens': None}, 'prompt_tokens_details': None}, 'model_name': 'Qwen/Qwen3-8B', 'system_fingerprint': '', 'id': '0198e0705dc5ff0a11313fcde69f7c5e', 'service_tier': None, 'finish_reason': 'stop', 'logprobs': None}, id='run--6975e4f2-cebb-41e1-8254-123e6dfbc51c-0', usage_metadata={'input_tokens': 380, 'output_tokens': 223, 'total_tokens': 603, 'input_token_details': {}, 'output_token_details': {'reasoning': 214}})]}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dacd5e3e",
   "metadata": {},
   "source": [
    "### Use it with MultiServerMCPClient:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "110d3200",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content=\"what's (3 + 5) x 12?\" additional_kwargs={} response_metadata={} id='672368aa-f52d-4a72-be86-0632e1db45af'\n",
      "content='\\n\\n' additional_kwargs={'tool_calls': [{'id': '0198e0758855fed7ecfa36472a830362', 'function': {'arguments': ' {\"a\": 3, \"b\": 5}', 'name': 'add'}, 'type': 'function', 'index': 0}, {'id': '0198e0758a681edb778707f0b2773440', 'function': {'arguments': ' {\"a\": 8, \"b\": 12}', 'name': 'multiply'}, 'type': 'function', 'index': 1}], 'refusal': None} response_metadata={'token_usage': {'completion_tokens': 333, 'prompt_tokens': 344, 'total_tokens': 677, 'completion_tokens_details': {'accepted_prediction_tokens': None, 'audio_tokens': None, 'reasoning_tokens': 305, 'rejected_prediction_tokens': None}, 'prompt_tokens_details': None}, 'model_name': 'Qwen/Qwen3-8B', 'system_fingerprint': '', 'id': '0198e0756c4cba5dc82e1b3f0aeb5258', 'service_tier': None, 'finish_reason': 'tool_calls', 'logprobs': None} id='run--6af1960c-0f50-44f2-9408-5e48e9fd1678-0' tool_calls=[{'name': 'add', 'args': {'a': 3, 'b': 5}, 'id': '0198e0758855fed7ecfa36472a830362', 'type': 'tool_call'}, {'name': 'multiply', 'args': {'a': 8, 'b': 12}, 'id': '0198e0758a681edb778707f0b2773440', 'type': 'tool_call'}] usage_metadata={'input_tokens': 344, 'output_tokens': 333, 'total_tokens': 677, 'input_token_details': {}, 'output_token_details': {'reasoning': 305}}\n",
      "content='8' name='add' id='a49863d1-e592-47fb-aaf1-f347ae9f5ffa' tool_call_id='0198e0758855fed7ecfa36472a830362'\n",
      "content='96' name='multiply' id='8d79b69e-9ce5-42c8-a47b-97c14523626d' tool_call_id='0198e0758a681edb778707f0b2773440'\n",
      "content='\\n\\nThe result of (3 + 5) x 12 is 96.' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 153, 'prompt_tokens': 416, 'total_tokens': 569, 'completion_tokens_details': {'accepted_prediction_tokens': None, 'audio_tokens': None, 'reasoning_tokens': 134, 'rejected_prediction_tokens': None}, 'prompt_tokens_details': None}, 'model_name': 'Qwen/Qwen3-8B', 'system_fingerprint': '', 'id': '0198e0758d2f929358af632242f3e0a5', 'service_tier': None, 'finish_reason': 'stop', 'logprobs': None} id='run--151d301a-9d80-4b2a-9742-656d30889aef-0' usage_metadata={'input_tokens': 416, 'output_tokens': 153, 'total_tokens': 569, 'input_token_details': {}, 'output_token_details': {'reasoning': 134}}\n",
      "content='what is the weather in New York?' additional_kwargs={} response_metadata={} id='0ac79648-a54c-4cef-8796-1e71e19e3255'\n",
      "content='\\n\\n' additional_kwargs={'tool_calls': [{'id': '0198e075ac4730fed8641d57542d8d64', 'function': {'arguments': ' {\"location\": \"New York\"}', 'name': 'get_weather'}, 'type': 'function', 'index': 0}], 'refusal': None} response_metadata={'token_usage': {'completion_tokens': 139, 'prompt_tokens': 339, 'total_tokens': 478, 'completion_tokens_details': {'accepted_prediction_tokens': None, 'audio_tokens': None, 'reasoning_tokens': 130, 'rejected_prediction_tokens': None}, 'prompt_tokens_details': None}, 'model_name': 'Qwen/Qwen3-8B', 'system_fingerprint': '', 'id': '0198e0759dcccb5394f424ae89344b81', 'service_tier': None, 'finish_reason': 'tool_calls', 'logprobs': None} id='run--b9f40215-10bd-4dcc-b807-7e7df3188ca2-0' tool_calls=[{'name': 'get_weather', 'args': {'location': 'New York'}, 'id': '0198e075ac4730fed8641d57542d8d64', 'type': 'tool_call'}] usage_metadata={'input_tokens': 339, 'output_tokens': 139, 'total_tokens': 478, 'input_token_details': {}, 'output_token_details': {'reasoning': 130}}\n",
      "content=\"It's always sunny in New York.\" name='get_weather' id='5e786111-4378-418b-a600-9b6065592a82' tool_call_id='0198e075ac4730fed8641d57542d8d64'\n",
      "content='\\n\\nThe current weather in New York is sunny. ☀️ Enjoy the beautiful day!' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 221, 'prompt_tokens': 380, 'total_tokens': 601, 'completion_tokens_details': {'accepted_prediction_tokens': None, 'audio_tokens': None, 'reasoning_tokens': 203, 'rejected_prediction_tokens': None}, 'prompt_tokens_details': None}, 'model_name': 'Qwen/Qwen3-8B', 'system_fingerprint': '', 'id': '0198e075ae5bed327179b32a99c5937d', 'service_tier': None, 'finish_reason': 'stop', 'logprobs': None} id='run--06b00cae-7d4a-448d-8906-7ad1ff698324-0' usage_metadata={'input_tokens': 380, 'output_tokens': 221, 'total_tokens': 601, 'input_token_details': {}, 'output_token_details': {'reasoning': 203}}\n"
     ]
    }
   ],
   "source": [
    "# Use server from examples/servers/streamable-http-stateless/\n",
    "from langchain_mcp_adapters.client import MultiServerMCPClient\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "\n",
    "client = MultiServerMCPClient(\n",
    "    {\n",
    "        \"math\": {\n",
    "            \"transport\": \"streamable_http\",\n",
    "            \"url\": \"http://localhost:3000/mcp/\"\n",
    "        },\n",
    "    }\n",
    ")\n",
    "tools = await client.get_tools()\n",
    "agent = create_react_agent(llm, tools)\n",
    "math_response = await agent.ainvoke({\"messages\": \"what's (3 + 5) x 12?\"})\n",
    "weather_response = await agent.ainvoke({\"messages\": \"what is the weather in New York?\"})\n",
    "for item in math_response['messages']:\n",
    "    print(item)\n",
    "for item in weather_response['messages']:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b5395e2",
   "metadata": {},
   "source": [
    "### Passing runtime headers\n",
    "连接到 MCP 服务器时，您可以使用连接配置中的标头字段包含自定义标头（例如，用于身份验证或跟踪）。以下传输支持此功能：\n",
    "- sse\n",
    "- streamable_http  \n",
    "\n",
    "只有 sse 和 streamable_http 传输支持运行时标头。这些标头随每个 HTTP 请求传递到 MCP 服务器。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "94b25461",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='what is the weather in nyc?' additional_kwargs={} response_metadata={} id='c5974a23-67a6-4e2e-a531-0a834de6493f'\n",
      "content='\\n\\n' additional_kwargs={'tool_calls': [{'id': '0198e078626f9ba9d11f927c34b64931', 'function': {'arguments': ' {\"location\": \"nyc\"}', 'name': 'get_weather'}, 'type': 'function', 'index': 0}], 'refusal': None} response_metadata={'token_usage': {'completion_tokens': 131, 'prompt_tokens': 339, 'total_tokens': 470, 'completion_tokens_details': {'accepted_prediction_tokens': None, 'audio_tokens': None, 'reasoning_tokens': 122, 'rejected_prediction_tokens': None}, 'prompt_tokens_details': None}, 'model_name': 'Qwen/Qwen3-8B', 'system_fingerprint': '', 'id': '0198e0784a2513e35ed64c64c3f404c6', 'service_tier': None, 'finish_reason': 'tool_calls', 'logprobs': None} id='run--ab08f77b-1861-43e4-a4c2-cff6d421c02b-0' tool_calls=[{'name': 'get_weather', 'args': {'location': 'nyc'}, 'id': '0198e078626f9ba9d11f927c34b64931', 'type': 'tool_call'}] usage_metadata={'input_tokens': 339, 'output_tokens': 131, 'total_tokens': 470, 'input_token_details': {}, 'output_token_details': {'reasoning': 122}}\n",
      "content=\"It's always sunny in nyc.\" name='get_weather' id='0a4a5232-cb78-427a-a470-9800a4ed37ac' tool_call_id='0198e078626f9ba9d11f927c34b64931'\n",
      "content='\\n\\nThe weather in NYC is sunny.' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 1158, 'prompt_tokens': 380, 'total_tokens': 1538, 'completion_tokens_details': {'accepted_prediction_tokens': None, 'audio_tokens': None, 'reasoning_tokens': 1150, 'rejected_prediction_tokens': None}, 'prompt_tokens_details': None}, 'model_name': 'Qwen/Qwen3-8B', 'system_fingerprint': '', 'id': '0198e0786525c0d90ff8349199b10794', 'service_tier': None, 'finish_reason': 'stop', 'logprobs': None} id='run--960d8667-fe98-4503-bad7-694002127f8f-0' usage_metadata={'input_tokens': 380, 'output_tokens': 1158, 'total_tokens': 1538, 'input_token_details': {}, 'output_token_details': {'reasoning': 1150}}\n"
     ]
    }
   ],
   "source": [
    "from langchain_mcp_adapters.client import MultiServerMCPClient\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "\n",
    "client = MultiServerMCPClient(\n",
    "    {\n",
    "        \"weather\": {\n",
    "            \"transport\": \"streamable_http\",\n",
    "            \"url\": \"http://localhost:3000/mcp\",\n",
    "            \"headers\": {\n",
    "                \"Authorization\": \"Bearer YOUR_TOKEN\",\n",
    "                \"X-Custom-Header\": \"custom-value\"\n",
    "            },\n",
    "        }\n",
    "    }\n",
    ")\n",
    "tools = await client.get_tools()\n",
    "agent = create_react_agent(llm, tools)\n",
    "response = await agent.ainvoke({\"messages\": \"what is the weather in nyc?\"})\n",
    "for item in response['messages']:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24330718",
   "metadata": {},
   "source": [
    "# Using with LangGraph StateGraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "08b781c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'messages': [HumanMessage(content=\"what's (3 + 5) x 12?\", additional_kwargs={}, response_metadata={}, id='34ce90d0-9643-4e70-bf80-6b7575022006'), AIMessage(content='\\n\\n', additional_kwargs={'tool_calls': [{'id': '0198e07f6fbd02546207d8b46c2f97ca', 'function': {'arguments': ' {\"a\": 3, \"b\": 5}', 'name': 'add'}, 'type': 'function', 'index': 0}, {'id': '0198e07f7404cee9a0ce13f4e14d54c3', 'function': {'arguments': ' {\"a\": 8, \"b\": 12}', 'name': 'multiply'}, 'type': 'function', 'index': 1}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 748, 'prompt_tokens': 585, 'total_tokens': 1333, 'completion_tokens_details': {'accepted_prediction_tokens': None, 'audio_tokens': None, 'reasoning_tokens': 720, 'rejected_prediction_tokens': None}, 'prompt_tokens_details': None}, 'model_name': 'Qwen/Qwen3-8B', 'system_fingerprint': '', 'id': '0198e07f0072bbc86f123e3ad3594988', 'service_tier': None, 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--b7ee1150-6df5-49cf-b204-0b5df985dfca-0', tool_calls=[{'name': 'add', 'args': {'a': 3, 'b': 5}, 'id': '0198e07f6fbd02546207d8b46c2f97ca', 'type': 'tool_call'}, {'name': 'multiply', 'args': {'a': 8, 'b': 12}, 'id': '0198e07f7404cee9a0ce13f4e14d54c3', 'type': 'tool_call'}], usage_metadata={'input_tokens': 585, 'output_tokens': 748, 'total_tokens': 1333, 'input_token_details': {}, 'output_token_details': {'reasoning': 720}}), ToolMessage(content='8', name='add', id='4be61822-5e55-44d9-8e74-00db5a02a4db', tool_call_id='0198e07f6fbd02546207d8b46c2f97ca'), ToolMessage(content='96', name='multiply', id='89159ee0-38cd-4960-90de-7a046ec0faff', tool_call_id='0198e07f7404cee9a0ce13f4e14d54c3'), AIMessage(content='\\n\\nThe value of (3 + 5) x 12 is $\\\\boxed{96}$.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 214, 'prompt_tokens': 657, 'total_tokens': 871, 'completion_tokens_details': {'accepted_prediction_tokens': None, 'audio_tokens': None, 'reasoning_tokens': 192, 'rejected_prediction_tokens': None}, 'prompt_tokens_details': None}, 'model_name': 'Qwen/Qwen3-8B', 'system_fingerprint': '', 'id': '0198e07f789598ab2fd56d7cf187e21c', 'service_tier': None, 'finish_reason': 'stop', 'logprobs': None}, id='run--63cb1a3c-0d90-46e8-a3ca-e5ac1ae61bc4-0', usage_metadata={'input_tokens': 657, 'output_tokens': 214, 'total_tokens': 871, 'input_token_details': {}, 'output_token_details': {'reasoning': 192}})]}\n",
      "{'messages': [HumanMessage(content='what is the weather in nyc?', additional_kwargs={}, response_metadata={}, id='ae9c1633-beb2-4d81-b991-3699db5170e5'), AIMessage(content='\\n\\n', additional_kwargs={'tool_calls': [{'id': '0198e07fa82611d0a90eb1465f857a5a', 'function': {'arguments': ' {\"location\": \"nyc\"}', 'name': 'get_weather'}, 'type': 'function', 'index': 0}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 182, 'prompt_tokens': 580, 'total_tokens': 762, 'completion_tokens_details': {'accepted_prediction_tokens': None, 'audio_tokens': None, 'reasoning_tokens': 173, 'rejected_prediction_tokens': None}, 'prompt_tokens_details': None}, 'model_name': 'Qwen/Qwen3-8B', 'system_fingerprint': '', 'id': '0198e07f94c2d20ea1f6af8246e00065', 'service_tier': None, 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--bc4f9f1d-def7-49f0-a793-3174a75e9d39-0', tool_calls=[{'name': 'get_weather', 'args': {'location': 'nyc'}, 'id': '0198e07fa82611d0a90eb1465f857a5a', 'type': 'tool_call'}], usage_metadata={'input_tokens': 580, 'output_tokens': 182, 'total_tokens': 762, 'input_token_details': {}, 'output_token_details': {'reasoning': 173}}), ToolMessage(content=\"It's always sunny in nyc.\", name='get_weather', id='06ae7949-3dad-4dce-b167-be32b7544c24', tool_call_id='0198e07fa82611d0a90eb1465f857a5a'), AIMessage(content='\\n\\nThe weather in NYC is sunny.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 254, 'prompt_tokens': 621, 'total_tokens': 875, 'completion_tokens_details': {'accepted_prediction_tokens': None, 'audio_tokens': None, 'reasoning_tokens': 246, 'rejected_prediction_tokens': None}, 'prompt_tokens_details': None}, 'model_name': 'Qwen/Qwen3-8B', 'system_fingerprint': '', 'id': '0198e07faaf7b25150260553d2e57060', 'service_tier': None, 'finish_reason': 'stop', 'logprobs': None}, id='run--c3df250f-04c0-495f-8a87-b349568dfb54-0', usage_metadata={'input_tokens': 621, 'output_tokens': 254, 'total_tokens': 875, 'input_token_details': {}, 'output_token_details': {'reasoning': 246}})]}\n"
     ]
    }
   ],
   "source": [
    "from langchain_mcp_adapters.client import MultiServerMCPClient\n",
    "from langgraph.graph import StateGraph, MessagesState, START\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langgraph.prebuilt import ToolNode, tools_condition\n",
    "\n",
    "model = ChatOpenAI(\n",
    "            model=\"Qwen/Qwen3-8B\",\n",
    "            # model=\"Qwen/Qwen3-30B-A3B-Instruct-2507\",\n",
    "            api_key=\"sk-jvjyawqpodlkxlywatvemcdykkrbvthhjyjyapyvtnifwlbl\",\n",
    "            base_url=\"https://api.siliconflow.cn/v1/\",\n",
    "        )\n",
    "\n",
    "client = MultiServerMCPClient(\n",
    "    {\n",
    "        # \"math\": {\n",
    "        #     \"command\": \"python\",\n",
    "        #     # Make sure to update to the full absolute path to your math_server.py file\n",
    "        #     \"args\": [\"/Users/lzc/TNTprojectZ/LangChainStudy/examples/math_server.py\"],\n",
    "        #     \"transport\": \"stdio\",\n",
    "        # },\n",
    "        # streamable_http版和Python代码函数重复。\n",
    "        \"math\": {\n",
    "            \"url\": \"http://localhost:3000/mcp/\",\n",
    "            \"transport\": \"streamable_http\",\n",
    "        },\n",
    "        \"weather\": {\n",
    "            # make sure you start your weather server on port 8000\n",
    "            \"url\": \"http://localhost:3000/mcp/\",\n",
    "            \"transport\": \"streamable_http\",\n",
    "        }\n",
    "    }\n",
    ")\n",
    "tools = await client.get_tools()\n",
    "\n",
    "def call_model(state: MessagesState):\n",
    "    response = model.bind_tools(tools).invoke(state[\"messages\"])\n",
    "    return {\"messages\": response}\n",
    "\n",
    "builder = StateGraph(MessagesState)\n",
    "builder.add_node(call_model)\n",
    "builder.add_node(ToolNode(tools))\n",
    "builder.add_edge(START, \"call_model\")\n",
    "builder.add_conditional_edges(\n",
    "    \"call_model\",\n",
    "    tools_condition,\n",
    ")\n",
    "builder.add_edge(\"tools\", \"call_model\")\n",
    "graph = builder.compile()\n",
    "math_response = await graph.ainvoke({\"messages\": \"what's (3 + 5) x 12?\"})\n",
    "weather_response = await graph.ainvoke({\"messages\": \"what is the weather in nyc?\"})\n",
    "\n",
    "print(math_response)\n",
    "print(weather_response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deepresearch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
