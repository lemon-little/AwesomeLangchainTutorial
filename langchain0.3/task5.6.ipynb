{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8c05a556",
   "metadata": {},
   "source": [
    "# Customize state\n",
    "## 1. Add keys to the state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a8d1f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated\n",
    "\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "    name: str\n",
    "    birthday: str"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13098140",
   "metadata": {},
   "source": [
    "## 2. Update the state inside the tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb4c5c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import ToolMessage\n",
    "from langchain_core.tools import InjectedToolCallId, tool\n",
    "\n",
    "from langgraph.types import Command, interrupt\n",
    "\n",
    "@tool\n",
    "# Note that because we are generating a ToolMessage for a state update, we\n",
    "# generally require the ID of the corresponding tool call. We can use\n",
    "# LangChain's InjectedToolCallId to signal that this argument should not\n",
    "# be revealed to the model in the tool's schema.\n",
    "def human_assistance(\n",
    "    name: str, birthday: str, tool_call_id: Annotated[str, InjectedToolCallId]\n",
    ") -> str:\n",
    "    \"\"\"Request assistance from a human.\"\"\"\n",
    "    human_response = interrupt(\n",
    "        {\n",
    "            \"question\": \"Is this correct?\",\n",
    "            \"name\": name,\n",
    "            \"birthday\": birthday,\n",
    "        },\n",
    "    )\n",
    "    # If the information is correct, update the state as-is.\n",
    "    if human_response.get(\"correct\", \"\").lower().startswith(\"y\"):\n",
    "        verified_name = name\n",
    "        verified_birthday = birthday\n",
    "        response = \"Correct\"\n",
    "    # Otherwise, receive information from the human reviewer.\n",
    "    else:\n",
    "        verified_name = human_response.get(\"name\", name)\n",
    "        verified_birthday = human_response.get(\"birthday\", birthday)\n",
    "        response = f\"Made a correction: {human_response}\"\n",
    "\n",
    "    # This time we explicitly update the state with a ToolMessage inside\n",
    "    # the tool.\n",
    "    state_update = {\n",
    "        \"name\": verified_name,\n",
    "        \"birthday\": verified_birthday,\n",
    "        \"messages\": [ToolMessage(response, tool_call_id=tool_call_id)],\n",
    "    }\n",
    "    # We return a Command object in the tool to update our state.\n",
    "    return Command(update=state_update)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05429fdd",
   "metadata": {},
   "source": [
    "## 3. Prompt the chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66264b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_input = (\n",
    "    \"Can you look up when LangGraph was released? \"\n",
    "    \"When you have the answer, use the human_assistance tool for review.\"\n",
    ")\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "events = graph.stream(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": user_input}]},\n",
    "    config,\n",
    "    stream_mode=\"values\",\n",
    ")\n",
    "for event in events:\n",
    "    if \"messages\" in event:\n",
    "        event[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b31f9cd",
   "metadata": {},
   "source": [
    "## 4. Add human assistance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "645704af",
   "metadata": {},
   "outputs": [],
   "source": [
    "human_command = Command(\n",
    "    resume={\n",
    "        \"name\": \"LangGraph\",\n",
    "        \"birthday\": \"Jan 17, 2024\",\n",
    "    },\n",
    ")\n",
    "\n",
    "events = graph.stream(human_command, config, stream_mode=\"values\")\n",
    "for event in events:\n",
    "    if \"messages\" in event:\n",
    "        event[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fcd8cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "snapshot = graph.get_state(config)\n",
    "\n",
    "{k: v for k, v in snapshot.values.items() if k in (\"name\", \"birthday\")}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "790d8a37",
   "metadata": {},
   "source": [
    "## 5. Manually update the state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60145536",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.update_state(config, {\"name\": \"LangGraph (library)\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef15d217",
   "metadata": {},
   "source": [
    "## 6. View the new value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "848f2d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "snapshot = graph.get_state(config)\n",
    "\n",
    "{k: v for k, v in snapshot.values.items() if k in (\"name\", \"birthday\")}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "011e3684",
   "metadata": {},
   "source": [
    "# å®Œæ•´ä»£ç "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "46698161",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated\n",
    "\n",
    "from langchain_tavily import TavilySearch\n",
    "from langchain_core.messages import ToolMessage\n",
    "from langchain_core.tools import InjectedToolCallId, tool\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.prebuilt import ToolNode, tools_condition\n",
    "from langgraph.types import Command, interrupt\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "import os\n",
    "\n",
    "os.environ[\"TAVILY_API_KEY\"] = \"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\"\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "        # model=\"Qwen/Qwen2.5-72B-Instruct\",\n",
    "        model=\"Qwen/Qwen3-8B\",\n",
    "        # ç¡…åŸºæµåŠ¨\n",
    "        api_key=\"sk-jvjyawqpodlkxlywatvemcdykkrbvthhjyjyapyvtnifwlbl\",\n",
    "        base_url=\"https://api.siliconflow.cn/v1/\",\n",
    "        # # modelscope \n",
    "        # base_url=\"https://api-inference.modelscope.cn/v1/\",\n",
    "        # api_key=\"ms-e2666046-2f3b-4c76-bcc0-e21f8ebf9ea1\",\n",
    "    )\n",
    "\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "    name: str\n",
    "    birthday: str\n",
    "\n",
    "@tool\n",
    "def human_assistance(\n",
    "    name: str, birthday: str, tool_call_id: Annotated[str, InjectedToolCallId]\n",
    ") -> str:\n",
    "    \"\"\"Request assistance from a human.\"\"\"\n",
    "    human_response = interrupt(\n",
    "        {\n",
    "            \"question\": \"Is this correct?\",\n",
    "            \"name\": name,\n",
    "            \"birthday\": birthday,\n",
    "        },\n",
    "    )\n",
    "    if human_response.get(\"correct\", \"\").lower().startswith(\"y\"):\n",
    "        verified_name = name\n",
    "        verified_birthday = birthday\n",
    "        response = \"Correct\"\n",
    "    else:\n",
    "        verified_name = human_response.get(\"name\", name)\n",
    "        verified_birthday = human_response.get(\"birthday\", birthday)\n",
    "        response = f\"Made a correction: {human_response}\"\n",
    "\n",
    "    state_update = {\n",
    "        \"name\": verified_name,\n",
    "        \"birthday\": verified_birthday,\n",
    "        \"messages\": [ToolMessage(response, tool_call_id=tool_call_id)],\n",
    "    }\n",
    "    return Command(update=state_update)\n",
    "\n",
    "\n",
    "tool = TavilySearch(max_results=2)\n",
    "tools = [tool, human_assistance]\n",
    "llm_with_tools = llm.bind_tools(tools)\n",
    "\n",
    "def chatbot(state: State):\n",
    "    message = llm_with_tools.invoke(state[\"messages\"])\n",
    "    assert(len(message.tool_calls) <= 1)\n",
    "    return {\"messages\": [message]}\n",
    "\n",
    "graph_builder = StateGraph(State)\n",
    "graph_builder.add_node(\"chatbot\", chatbot)\n",
    "\n",
    "tool_node = ToolNode(tools=tools)\n",
    "graph_builder.add_node(\"tools\", tool_node)\n",
    "\n",
    "graph_builder.add_conditional_edges(\n",
    "    \"chatbot\",\n",
    "    tools_condition,\n",
    ")\n",
    "graph_builder.add_edge(\"tools\", \"chatbot\")\n",
    "graph_builder.add_edge(START, \"chatbot\")\n",
    "\n",
    "memory = InMemorySaver()\n",
    "graph = graph_builder.compile(checkpointer=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bfd95f10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Can you look up when LangGraph was released? When you have the answer, use the human_assistance tool for review.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  tavily_search (0198e61441983ae72eac646c895171ea)\n",
      " Call ID: 0198e61441983ae72eac646c895171ea\n",
      "  Args:\n",
      "    query: LangGraph release date\n",
      "    search_depth: advanced\n",
      "    time_range: year\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: tavily_search\n",
      "\n",
      "{\"query\": \"LangGraph release date\", \"follow_up_questions\": null, \"answer\": null, \"images\": [], \"results\": [{\"url\": \"https://en.wikipedia.org/wiki/LangChain\", \"title\": \"LangChain\", \"content\": \"| Connery | No | Yes | Commercial | API actions | https://python.langchain.com/docs/integrations/tools/connery | | Dall-E Image Generator | No | Yes | Proprietary | Text-to-image generation | https://python.langchain.com/docs/integrations/tools/dalle_image_generator | | DuckDuckGo Search | No | No | Open source | Privacy-focused search | https://python.langchain.com/docs/integrations/tools/ddg | | Google Scholar | Yes | Yes | Proprietary | Scholarly article search | https://python.langchain.com/docs/integrations/tools/google_scholar | | HuggingFace Hub | No | No | Open source | Hugging Face models, datasets | https://python.langchain.com/docs/integrations/tools/huggingface_tools | | SerpAPI | No | Yes | Commercial | Search engine results page scraping | https://python.langchain.com/docs/integrations/tools/serpapi | | Wikidata | No | No | Open source | Structured data access | https://python.langchain.com/docs/integrations/tools/wikidata | | Wikipedia | No | No | Open source | Wikipedia access | https://python.langchain.com/docs/integrations/tools/wikipedia |\", \"score\": 0.98595, \"raw_content\": null}, {\"url\": \"https://github.com/langchain-ai/langgraph/releases\", \"title\": \"Releases Â· langchain-ai/langgraph - GitHub\", \"content\": \"[Please reload this page.](https://github.com/langchain-ai/langgraph/security) *   feat(langgraph): Add context coercion for LangGraph runtime (#5736) *   `get_config_jsonschema` is deprecated in favor of `get_context_jsonschema` (though this is generally only used for graph introspection and not by most langgraph users) `create_react_agent` can now dynamically choose both the model and tools at runtime using a custom context object: from langgraph.prebuilt import create_react_agent | `from langgraph.constants import Send` | `from langgraph.types import Send` | âš ï¸ Deprecated - Will be removed in V2 | | `from langgraph.constants import Interrupt` | `from langgraph.types import Interrupt` | âš ï¸ Deprecated - Will be removed in V2 | *   feat(langgraph): new context api (replacing `config['configurable']` and `config_schema`) (#5243) *   change[langgraph]: clean up `Interrupt` interface for v1 (#5405) *   feat(langgraph): new context api (replacing `config['configurable']` and `config_schema`) (#5243)\", \"score\": 0.98538, \"raw_content\": null}], \"response_time\": 3.39, \"request_id\": \"6156c14a-c731-46d0-9b55-9f79e1f4464c\"}\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  human_assistance (0198e615fbfaa91e8de1175253bf8644)\n",
      " Call ID: 0198e615fbfaa91e8de1175253bf8644\n",
      "  Args:\n",
      "    name: LangGraph\n",
      "    birthday: release date\n"
     ]
    }
   ],
   "source": [
    "user_input = (\n",
    "    \"Can you look up when LangGraph was released? \"\n",
    "    \"When you have the answer, use the human_assistance tool for review.\"\n",
    ")\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "events = graph.stream(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": user_input}]},\n",
    "    config,\n",
    "    stream_mode=\"values\",\n",
    ")\n",
    "for event in events:\n",
    "    if \"messages\" in event:\n",
    "        event[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "102f080a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  human_assistance (0198e615fbfaa91e8de1175253bf8644)\n",
      " Call ID: 0198e615fbfaa91e8de1175253bf8644\n",
      "  Args:\n",
      "    name: LangGraph\n",
      "    birthday: release date\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: human_assistance\n",
      "\n",
      "Made a correction: {'name': 'LangGraph', 'birthday': 'Jan 17, 2024'}\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "\n",
      "\n",
      "LangGraph was released on **January 17, 2024**, according to the human assistant's verification. For more details about the release or its features, you might explore the [GitHub releases page](https://github.com/langchain-ai/langgraph/releases). Let me know if you'd like further clarification!\n"
     ]
    }
   ],
   "source": [
    "human_command = Command(\n",
    "    resume={\n",
    "        \"name\": \"LangGraph\",\n",
    "        \"birthday\": \"Jan 17, 2024\",\n",
    "    },\n",
    ")\n",
    "\n",
    "events = graph.stream(human_command, config, stream_mode=\"values\")\n",
    "for event in events:\n",
    "    if \"messages\" in event:\n",
    "        event[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bdccf8ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'LangGraph', 'birthday': 'Jan 17, 2024'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snapshot = graph.get_state(config)\n",
    "\n",
    "{k: v for k, v in snapshot.values.items() if k in (\"name\", \"birthday\")}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9cd962ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'LangGraph (library)', 'birthday': 'Jan 17, 2024'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.update_state(config, {\"name\": \"LangGraph (library)\"})\n",
    "\n",
    "snapshot = graph.get_state(config)\n",
    "\n",
    "{k: v for k, v in snapshot.values.items() if k in (\"name\", \"birthday\")}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fce5070a",
   "metadata": {},
   "source": [
    "æµ‹è¯•"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d0b17431",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='Can you look up when LangGraph was released? When you have the answer, use the human_assistance tool for review.', additional_kwargs={}, response_metadata={}, id='fb32e86d-4f74-4d1e-9764-a37ef4c1c4c0'),\n",
       "  AIMessage(content='\\n\\n', additional_kwargs={'tool_calls': [{'id': '0198e61441983ae72eac646c895171ea', 'function': {'arguments': ' {\"query\": \"LangGraph release date\", \"search_depth\": \"advanced\", \"time_range\": \"year\"}', 'name': 'tavily_search'}, 'type': 'function', 'index': 0}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 1999, 'prompt_tokens': 1914, 'total_tokens': 3913, 'completion_tokens_details': {'accepted_prediction_tokens': None, 'audio_tokens': None, 'reasoning_tokens': 1974, 'rejected_prediction_tokens': None}, 'prompt_tokens_details': None}, 'model_name': 'Qwen/Qwen3-8B', 'system_fingerprint': '', 'id': '0198e6136008a69b669afb5dab505e8f', 'service_tier': None, 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--e5ec90af-4cd7-44b8-a4a3-8312d3db3f97-0', tool_calls=[{'name': 'tavily_search', 'args': {'query': 'LangGraph release date', 'search_depth': 'advanced', 'time_range': 'year'}, 'id': '0198e61441983ae72eac646c895171ea', 'type': 'tool_call'}], usage_metadata={'input_tokens': 1914, 'output_tokens': 1999, 'total_tokens': 3913, 'input_token_details': {}, 'output_token_details': {'reasoning': 1974}}),\n",
       "  ToolMessage(content='{\"query\": \"LangGraph release date\", \"follow_up_questions\": null, \"answer\": null, \"images\": [], \"results\": [{\"url\": \"https://en.wikipedia.org/wiki/LangChain\", \"title\": \"LangChain\", \"content\": \"| Connery | No | Yes | Commercial | API actions | https://python.langchain.com/docs/integrations/tools/connery | | Dall-E Image Generator | No | Yes | Proprietary | Text-to-image generation | https://python.langchain.com/docs/integrations/tools/dalle_image_generator | | DuckDuckGo Search | No | No | Open source | Privacy-focused search | https://python.langchain.com/docs/integrations/tools/ddg | | Google Scholar | Yes | Yes | Proprietary | Scholarly article search | https://python.langchain.com/docs/integrations/tools/google_scholar | | HuggingFace Hub | No | No | Open source | Hugging Face models, datasets | https://python.langchain.com/docs/integrations/tools/huggingface_tools | | SerpAPI | No | Yes | Commercial | Search engine results page scraping | https://python.langchain.com/docs/integrations/tools/serpapi | | Wikidata | No | No | Open source | Structured data access | https://python.langchain.com/docs/integrations/tools/wikidata | | Wikipedia | No | No | Open source | Wikipedia access | https://python.langchain.com/docs/integrations/tools/wikipedia |\", \"score\": 0.98595, \"raw_content\": null}, {\"url\": \"https://github.com/langchain-ai/langgraph/releases\", \"title\": \"Releases Â· langchain-ai/langgraph - GitHub\", \"content\": \"[Please reload this page.](https://github.com/langchain-ai/langgraph/security) *   feat(langgraph): Add context coercion for LangGraph runtime (#5736) *   `get_config_jsonschema` is deprecated in favor of `get_context_jsonschema` (though this is generally only used for graph introspection and not by most langgraph users) `create_react_agent` can now dynamically choose both the model and tools at runtime using a custom context object: from langgraph.prebuilt import create_react_agent | `from langgraph.constants import Send` | `from langgraph.types import Send` | âš ï¸ Deprecated - Will be removed in V2 | | `from langgraph.constants import Interrupt` | `from langgraph.types import Interrupt` | âš ï¸ Deprecated - Will be removed in V2 | *   feat(langgraph): new context api (replacing `config[\\'configurable\\']` and `config_schema`) (#5243) *   change[langgraph]: clean up `Interrupt` interface for v1 (#5405) *   feat(langgraph): new context api (replacing `config[\\'configurable\\']` and `config_schema`) (#5243)\", \"score\": 0.98538, \"raw_content\": null}], \"response_time\": 3.39, \"request_id\": \"6156c14a-c731-46d0-9b55-9f79e1f4464c\"}', name='tavily_search', id='2e52a9ae-c4cd-499d-beaf-654319fa7bfd', tool_call_id='0198e61441983ae72eac646c895171ea'),\n",
       "  AIMessage(content='\\n\\n', additional_kwargs={'tool_calls': [{'id': '0198e615fbfaa91e8de1175253bf8644', 'function': {'arguments': ' {\"name\": \"LangGraph\", \"birthday\": \"release date\"}', 'name': 'human_assistance'}, 'type': 'function', 'index': 0}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 2606, 'prompt_tokens': 2651, 'total_tokens': 5257, 'completion_tokens_details': {'accepted_prediction_tokens': None, 'audio_tokens': None, 'reasoning_tokens': 2590, 'rejected_prediction_tokens': None}, 'prompt_tokens_details': None}, 'model_name': 'Qwen/Qwen3-8B', 'system_fingerprint': '', 'id': '0198e6145dc16949cd59760a2d9e8341', 'service_tier': None, 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--e529c637-4269-4763-8938-a5f6ba58cc9a-0', tool_calls=[{'name': 'human_assistance', 'args': {'name': 'LangGraph', 'birthday': 'release date'}, 'id': '0198e615fbfaa91e8de1175253bf8644', 'type': 'tool_call'}], usage_metadata={'input_tokens': 2651, 'output_tokens': 2606, 'total_tokens': 5257, 'input_token_details': {}, 'output_token_details': {'reasoning': 2590}}),\n",
       "  ToolMessage(content=\"Made a correction: {'name': 'LangGraph', 'birthday': 'Jan 17, 2024'}\", name='human_assistance', id='6f96476a-5974-4d32-b38e-f443a7a90066', tool_call_id='0198e615fbfaa91e8de1175253bf8644'),\n",
       "  AIMessage(content=\"\\n\\nLangGraph was released on **January 17, 2024**, according to the human assistant's verification. For more details about the release or its features, you might explore the [GitHub releases page](https://github.com/langchain-ai/langgraph/releases). Let me know if you'd like further clarification!\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 364, 'prompt_tokens': 2718, 'total_tokens': 3082, 'completion_tokens_details': {'accepted_prediction_tokens': None, 'audio_tokens': None, 'reasoning_tokens': 297, 'rejected_prediction_tokens': None}, 'prompt_tokens_details': None}, 'model_name': 'Qwen/Qwen3-8B', 'system_fingerprint': '', 'id': '0198e615fff6f2532dea4d1fcc3a7908', 'service_tier': None, 'finish_reason': 'stop', 'logprobs': None}, id='run--adc19be6-5ba8-4fb5-b0f0-8f858b411d69-0', usage_metadata={'input_tokens': 2718, 'output_tokens': 364, 'total_tokens': 3082, 'input_token_details': {}, 'output_token_details': {'reasoning': 297}}),\n",
       "  HumanMessage(content='å¦‚ä½•ä½¿ç”¨LangGraphæ¥æ„å»ºä¸€ä¸ª AI æ™ºèƒ½ä½“ï¼Ÿè¯·ç»™å‡ºå…·ä½“çš„æ­¥éª¤ï¼Ÿ', additional_kwargs={}, response_metadata={}, id='edcf69e3-c7e3-4ae2-93e0-993049d89e73'),\n",
       "  AIMessage(content='\\n\\n', additional_kwargs={'tool_calls': [{'id': '0198e61ab91138d8f052e5915c5e902c', 'function': {'arguments': ' {\"query\": \"How to use LangGraph to build an AI agent steps\", \"search_depth\": \"advanced\", \"topic\": \"general\", \"include_domains\": [\"python.langchain.com\", \"github.com\"]}', 'name': 'tavily_search'}, 'type': 'function', 'index': 0}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 1033, 'prompt_tokens': 2813, 'total_tokens': 3846, 'completion_tokens_details': {'accepted_prediction_tokens': None, 'audio_tokens': None, 'reasoning_tokens': 987, 'rejected_prediction_tokens': None}, 'prompt_tokens_details': None}, 'model_name': 'Qwen/Qwen3-8B', 'system_fingerprint': '', 'id': '0198e61a370cc8b5ca114c2c4b8a1480', 'service_tier': None, 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--d9684e68-d02c-4d2b-a794-bc73ebca8f24-0', tool_calls=[{'name': 'tavily_search', 'args': {'query': 'How to use LangGraph to build an AI agent steps', 'search_depth': 'advanced', 'topic': 'general', 'include_domains': ['python.langchain.com', 'github.com']}, 'id': '0198e61ab91138d8f052e5915c5e902c', 'type': 'tool_call'}], usage_metadata={'input_tokens': 2813, 'output_tokens': 1033, 'total_tokens': 3846, 'input_token_details': {}, 'output_token_details': {'reasoning': 987}}),\n",
       "  ToolMessage(content='{\"query\": \"How to use LangGraph to build an AI agent steps\", \"follow_up_questions\": null, \"answer\": null, \"images\": [], \"results\": [{\"url\": \"https://github.com/ksm26/AI-Agents-in-LangGraph/blob/main/README.md\", \"title\": \"AI-Agents-in-LangGraph/README.md at main - GitHub\", \"content\": \"In this course, you\\'ll explore key principles of designing AI agents with LangGraph, learning how to build flow-based applications and enhance agent capabilities. Here\\'s what you can expect to learn and experience:\\\\n\\\\n1.   ğŸ› ï¸ Building from Scratch: Learn to build an agent from scratch using Python and an LLM, understanding the division of tasks between the LLM and the code around it.\\\\n\\\\nImage 2 [...] 1.   ğŸ”„ LangGraph Implementation: Rebuild your agent using LangGraph, learning about its components and how to combine them effectively.\\\\n\\\\nImage 3Image 4\\\\n\\\\n1.   ğŸ” Agentic Search: Explore agentic search, which retrieves multiple answers in a predictable format, enhancing the agentâ€™s built-in knowledge.\\\\n\\\\nImage 5 [...] By the end of the course, youâ€™ll have hands-on experience with LangGraphâ€™s core components and a solid understanding of how to build and enhance AI agents effectively.\\\\n\\\\nKey Points\\\\n----------\\\\n\\\\n[](\\\\n\\\\n   ğŸ§© Learn about LangGraphâ€™s components and how they enable the development, debugging, and maintenance of AI agents.\\\\n   ğŸ“ˆ Integrate agentic search capabilities to enhance agent knowledge and performance.\\\\n   ğŸŒŸ Learn directly from LangChain founder Harrison Chase and Tavily founder Rotem Weiss.\", \"score\": 0.83290404, \"raw_content\": null}, {\"url\": \"https://github.com/JoshuaC215/agent-service-toolkit\", \"title\": \"Full toolkit for running an AI agent service built with LangGraph ...\", \"content\": \"This project offers a template for you to easily build and run your own agents using the LangGraph framework. It demonstrates a complete setup from agent definition to user interface, making it easier to get started with LangGraph-based projects by providing a full, robust toolkit.\\\\n\\\\nğŸ¥ Watch a video walkthrough of the repo and app\\\\n\\\\n## Overview\\\\n\\\\n### Try the app!\\\\n\\\\n### Quickstart\\\\n\\\\nRun directly in python\\\\n\\\\n```\\\\n# At least one LLM API key is required\\\\necho \\'OPENAI_API_KEY=your_openai_api_key\\' >> .env [...] 1. Add your new agent to the `src/agents` directory. You can copy `research_assistant.py` or `chatbot.py` and modify it to change the agent\\'s behavior and tools.\\\\n2. Import and add your new agent to the `agents` dictionary in `src/agents/agents.py`. Your agent can be called by `/<your_agent_name>/invoke` or `/<your_agent_name>/stream`.\\\\n3. Adjust the Streamlit interface in `src/streamlit_app.py` to match your agent\\'s capabilities.\\\\n\\\\n### Handling Private Credential files [...] `langgraph-cli[inmem]` is installed with `uv sync`. You can simply add your `.env` file to the root directory as described above, and then launch LangGraph Studio with `langgraph dev`. Customize `langgraph.json` as needed. See the local quickstart to learn more.\\\\n\\\\n### Local development without Docker\\\\n\\\\nYou can also run the agent service and the Streamlit app locally without Docker, just using a Python virtual environment.\\\\n\\\\n1. Create a virtual environment and install dependencies:\", \"score\": 0.76385427, \"raw_content\": null}], \"response_time\": 1.86, \"request_id\": \"f636afcd-4e14-49be-887a-0c75096fab5c\"}', name='tavily_search', id='73f4399f-2a76-4176-a60f-8268c3c13000', tool_call_id='0198e61ab91138d8f052e5915c5e902c'),\n",
       "  AIMessage(content='\\n\\nä»¥ä¸‹æ˜¯ä½¿ç”¨LangGraphæ„å»ºAIæ™ºèƒ½ä½“çš„å…·ä½“æ­¥éª¤ï¼š\\n\\n---\\n\\n### **æ­¥éª¤ 1: ç¯å¢ƒå‡†å¤‡**\\n1. **å®‰è£…ä¾èµ–**  \\n   - ä½¿ç”¨Pythonè™šæ‹Ÿç¯å¢ƒåˆ›å»ºé¡¹ç›®ï¼š  \\n     ```bash\\n     python -m venv langgraph_env\\n     source langgraph_env/bin/activate  # Linux/Mac  \\n     langgraph_env\\\\Scripts\\\\activate      # Windows  \\n     ```\\n   - å®‰è£…LangGraphåº“ï¼š  \\n     ```bash\\n     pip install langgraph\\n     ```\\n   - å®‰è£…é¢å¤–å·¥å…·ï¼ˆå¦‚Streamlitï¼‰ï¼š  \\n     ```bash\\n     pip install streamlit\\n     ```\\n\\n2. **é…ç½®APIå¯†é’¥**  \\n   - åœ¨é¡¹ç›®æ ¹ç›®å½•åˆ›å»º`.env`æ–‡ä»¶ï¼Œå¹¶æ·»åŠ å¿…è¦çš„APIå¯†é’¥ï¼ˆå¦‚OpenAI API Keyï¼‰ï¼š  \\n     ```env\\n     OPENAI_API_KEY=your_openai_api_key\\n     ```\\n\\n---\\n\\n### **æ­¥éª¤ 2: å®šä¹‰AIæ™ºèƒ½ä½“**\\n1. **åˆ›å»ºä»£ç†æ–‡ä»¶**  \\n   - åœ¨`src/agents`ç›®å½•ä¸‹ï¼Œå¤åˆ¶ç°æœ‰æ¨¡æ¿ï¼ˆå¦‚`research_assistant.py`æˆ–`chatbot.py`ï¼‰å¹¶ä¿®æ”¹ï¼š  \\n     ```python\\n     from langgraph.prebuilt import create_react_agent\\n     from langchain.chat import ChatOpenAI\\n     from langchain.tools import Tool\\n\\n     llm = ChatOpenAI(model=\"gpt-3.5-turbo\")\\n     tools = [Tool(name=\"search\", func=search_function, description=\"æœç´¢å·¥å…·\")]\\n\\n     agent = create_react_agent(llm, tools, ...)\\n     ```\\n\\n2. **æ³¨å†Œä»£ç†åˆ°æœåŠ¡**  \\n   - åœ¨`src/agents/agents.py`ä¸­ï¼Œå°†æ–°ä»£ç†æ·»åŠ åˆ°`agents`å­—å…¸ï¼š  \\n     ```python\\n     agents = {\\n         \"research_agent\": ResearchAgent(),\\n         \"your_agent_name\": YourAgent(),\\n     }\\n     ```\\n\\n---\\n\\n### **æ­¥éª¤ 3: é›†æˆå·¥å…·ä¸åŠŸèƒ½**\\n1. **æ·»åŠ å·¥å…·æ”¯æŒ**  \\n   - ä½¿ç”¨`create_react_agent`åŠ¨æ€é€‰æ‹©æ¨¡å‹å’Œå·¥å…·ï¼Œä¾‹å¦‚ï¼š  \\n     ```python\\n     from langgraph.constants import Send\\n     from langgraph.types import Send\\n     ```\\n   - é…ç½®å·¥å…·å‚æ•°ï¼ˆå¦‚æœç´¢èŒƒå›´ã€æ•°æ®æ ¼å¼ï¼‰ã€‚\\n\\n2. **å®ç°åŸºäºä»£ç†çš„æœç´¢**  \\n   - é€šè¿‡`langgraph`çš„APIè°ƒç”¨å¤šå·¥å…·åä½œï¼Œè·å–ç»“æ„åŒ–ç»“æœï¼š  \\n     ```python\\n     response = agent.invoke({\"input\": \"What is the latest AI news?\"})\\n     ```\\n\\n---\\n\\n### **æ­¥éª¤ 4: è®¾ç½®ç”¨æˆ·ç•Œé¢**\\n1. **è°ƒæ•´Streamlitç•Œé¢**  \\n   - ä¿®æ”¹`src/streamlit_app.py`ä»¥é€‚é…ä»£ç†åŠŸèƒ½ï¼š  \\n     ```python\\n     import streamlit as st\\n     from langgraph import YourAgent\\n\\n     st.title(\"AI Agent Interface\")\\n     user_input = st.text_input(\"Enter your query:\")\\n     if user_input:\\n         result = YourAgent().invoke({\"input\": user_input})\\n         st.write(result)\\n     ```\\n\\n2. **å¯åŠ¨ç•Œé¢**  \\n   - è¿è¡ŒStreamlitåº”ç”¨ï¼š  \\n     ```bash\\n     streamlit run src/streamlit_app.py\\n     ```\\n\\n---\\n\\n### **æ­¥éª¤ 5: è°ƒè¯•ä¸éƒ¨ç½²**\\n1. **æœ¬åœ°å¼€å‘**  \\n   - æ— éœ€Dockerï¼Œç›´æ¥é€šè¿‡Pythonè™šæ‹Ÿç¯å¢ƒè°ƒè¯•ï¼š  \\n     ```bash\\n     uv sync  # åŒæ­¥ä¾èµ–\\n     langgraph dev  # å¯åŠ¨LangGraph Studio\\n     ```\\n\\n2. **éƒ¨ç½²æœåŠ¡**  \\n   - å°†ä»£ç†æœåŠ¡é›†æˆåˆ°ç”Ÿäº§ç¯å¢ƒï¼Œç¡®ä¿APIå¯†é’¥å’Œå·¥å…·é…ç½®å®‰å…¨ã€‚\\n\\n---\\n\\n### **ç¤ºä¾‹èµ„æº**\\n- **æ•™ç¨‹ä»“åº“**ï¼š[AI-Agents-in-LangGraph](https://github.com/ksm26/AI-Agents-in-LangGraph)  \\n- **å·¥å…·åŒ…**ï¼š[Agent Service Toolkit](https://github.com/JoshuaC215/agent-service-toolkit)  \\n- **LangGraphå®˜æ–¹æ–‡æ¡£**ï¼š[LangGraph Docs](https://python.langchain.com/docs/integrations/tools/langgraph)\\n\\nè‹¥éœ€è¿›ä¸€æ­¥ä¼˜åŒ–æˆ–å…·ä½“ä»£ç ç¤ºä¾‹ï¼Œå¯å‚è€ƒä¸Šè¿°é“¾æ¥ä¸­çš„è¯¦ç»†è¯´æ˜ï¼ ğŸš€', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 1315, 'prompt_tokens': 3727, 'total_tokens': 5042, 'completion_tokens_details': {'accepted_prediction_tokens': None, 'audio_tokens': None, 'reasoning_tokens': 437, 'rejected_prediction_tokens': None}, 'prompt_tokens_details': None}, 'model_name': 'Qwen/Qwen3-8B', 'system_fingerprint': '', 'id': '0198e61ace31035966d035a84058b88f', 'service_tier': None, 'finish_reason': 'stop', 'logprobs': None}, id='run--20514a04-4fde-432a-b40a-b48c0568792a-0', usage_metadata={'input_tokens': 3727, 'output_tokens': 1315, 'total_tokens': 5042, 'input_token_details': {}, 'output_token_details': {'reasoning': 437}})],\n",
       " 'name': 'LangGraph (library)',\n",
       " 'birthday': 'Jan 17, 2024'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"å¦‚ä½•ä½¿ç”¨LangGraphæ¥æ„å»ºä¸€ä¸ª AI æ™ºèƒ½ä½“ï¼Ÿè¯·ç»™å‡ºå…·ä½“çš„æ­¥éª¤ï¼Ÿ\"}]},\n",
    "    config,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ddaaa5bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "å¦‚ä½•ä½¿ç”¨LangGraphæ¥æ„å»ºä¸€ä¸ª AI æ™ºèƒ½ä½“ï¼Ÿè¯·ç»™å‡ºå…·ä½“çš„æ­¥éª¤ï¼Ÿ\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "\n",
      "\n",
      "ä»¥ä¸‹æ˜¯ä½¿ç”¨LangGraphæ„å»ºAIæ™ºèƒ½ä½“çš„å…·ä½“æ­¥éª¤ï¼š\n",
      "\n",
      "---\n",
      "\n",
      "### **æ­¥éª¤ 1: ç¯å¢ƒå‡†å¤‡**\n",
      "1. **åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ**  \n",
      "   ```bash\n",
      "   python -m venv langgraph_env\n",
      "   source langgraph_env/bin/activate  # Linux/Mac  \n",
      "   langgraph_env\\Scripts\\activate      # Windows  \n",
      "   ```\n",
      "2. **å®‰è£…ä¾èµ–**  \n",
      "   ```bash\n",
      "   pip install langgraph langchain streamlit\n",
      "   ```\n",
      "\n",
      "---\n",
      "\n",
      "### **æ­¥éª¤ 2: å®šä¹‰AIæ™ºèƒ½ä½“**\n",
      "1. **åˆ›å»ºä»£ç†é€»è¾‘**  \n",
      "   åœ¨`src/agents`ç›®å½•ä¸‹ï¼Œç¼–å†™ä»£ç†é€»è¾‘æ–‡ä»¶ï¼ˆå¦‚`research_agent.py`ï¼‰ï¼š  \n",
      "   ```python\n",
      "   from langgraph.prebuilt import create_react_agent\n",
      "   from langchain.chat import ChatOpenAI\n",
      "   from langchain.tools import Tool\n",
      "\n",
      "   llm = ChatOpenAI(model=\"gpt-3.5-turbo\")\n",
      "   tools = [Tool(name=\"search\", func=search_function, description=\"æœç´¢å·¥å…·\")]\n",
      "\n",
      "   agent = create_react_agent(llm, tools, ...)\n",
      "   ```\n",
      "2. **æ³¨å†Œä»£ç†åˆ°æœåŠ¡**  \n",
      "   åœ¨`src/agents/agents.py`ä¸­ï¼Œå°†ä»£ç†æ·»åŠ åˆ°å…¨å±€å­—å…¸ï¼š  \n",
      "   ```python\n",
      "   agents = {\n",
      "       \"research_agent\": ResearchAgent(),\n",
      "       \"your_agent_name\": YourAgent(),\n",
      "   }\n",
      "   ```\n",
      "\n",
      "---\n",
      "\n",
      "### **æ­¥éª¤ 3: é›†æˆå·¥å…·ä¸åŠŸèƒ½**\n",
      "1. **é…ç½®å·¥å…·å‚æ•°**  \n",
      "   ä½¿ç”¨`create_react_agent`åŠ¨æ€é€‰æ‹©æ¨¡å‹å’Œå·¥å…·ï¼Œä¾‹å¦‚ï¼š  \n",
      "   ```python\n",
      "   from langgraph.constants import Send\n",
      "   from langgraph.types import Send\n",
      "   ```\n",
      "2. **å®ç°åŸºäºä»£ç†çš„æœç´¢**  \n",
      "   é€šè¿‡å¤šå·¥å…·åä½œè·å–ç»“æ„åŒ–ç»“æœï¼š  \n",
      "   ```python\n",
      "   response = agent.invoke({\"input\": \"What is the latest AI news?\"})\n",
      "   ```\n",
      "\n",
      "---\n",
      "\n",
      "### **æ­¥éª¤ 4: è®¾ç½®ç”¨æˆ·ç•Œé¢**\n",
      "1. **è°ƒæ•´Streamlitç•Œé¢**  \n",
      "   ä¿®æ”¹`src/streamlit_app.py`ä»¥é€‚é…ä»£ç†åŠŸèƒ½ï¼š  \n",
      "   ```python\n",
      "   import streamlit as st\n",
      "   from langgraph import YourAgent\n",
      "\n",
      "   st.title(\"AI Agent Interface\")\n",
      "   user_input = st.text_input(\"Enter your query:\")\n",
      "   if user_input:\n",
      "       result = YourAgent().invoke({\"input\": user_input})\n",
      "       st.write(result)\n",
      "   ```\n",
      "2. **å¯åŠ¨ç•Œé¢**  \n",
      "   ```bash\n",
      "   streamlit run src/streamlit_app.py\n",
      "   ```\n",
      "\n",
      "---\n",
      "\n",
      "### **æ­¥éª¤ 5: è°ƒè¯•ä¸éƒ¨ç½²**\n",
      "1. **æœ¬åœ°è°ƒè¯•**  \n",
      "   ä½¿ç”¨`langgraph dev`å¯åŠ¨å¼€å‘æœåŠ¡å™¨ï¼š  \n",
      "   ```bash\n",
      "   langgraph dev\n",
      "   ```\n",
      "2. **éƒ¨ç½²æœåŠ¡**  \n",
      "   å°†ä»£ç†æœåŠ¡é›†æˆåˆ°ç”Ÿäº§ç¯å¢ƒï¼Œç¡®ä¿APIå¯†é’¥å®‰å…¨ã€‚\n",
      "\n",
      "---\n",
      "\n",
      "### **å…³é”®ç‚¹**\n",
      "- **ç»„ä»¶å­¦ä¹ **ï¼šç†è§£LangGraphçš„æ¨¡å—åŒ–è®¾è®¡ï¼ˆå¦‚`config`, `tools`, `agent`ï¼‰ã€‚\n",
      "- **å·¥å…·é›†æˆ**ï¼šé€šè¿‡`create_react_agent`åŠ¨æ€ç»‘å®šå·¥å…·ï¼Œå¦‚æœç´¢ã€æ•°æ®åˆ†æç­‰ã€‚\n",
      "- **ç•Œé¢ä¼˜åŒ–**ï¼šè‡ªå®šä¹‰Streamlitç•Œé¢ä»¥æå‡ç”¨æˆ·ä½“éªŒã€‚\n",
      "\n",
      "### **å‚è€ƒèµ„æ–™**\n",
      "- **æ•™ç¨‹ä»“åº“**ï¼š[AI-Agents-in-LangGraph](https://github.com/ksm26/AI-Agents-in-LangGraph)  \n",
      "- **å·¥å…·åŒ…**ï¼š[Agent Service Toolkit](https://github.com/JoshuaC215/agent-service-toolkit)  \n",
      "- **å®˜æ–¹æ–‡æ¡£**ï¼š[LangGraph Docs](https://python.langchain.com/docs/integrations/tools/langgraph)\n",
      "\n",
      "å¦‚éœ€è¿›ä¸€æ­¥ä¼˜åŒ–æˆ–ä»£ç ç¤ºä¾‹ï¼Œå¯å‚è€ƒä¸Šè¿°é“¾æ¥ï¼ ğŸš€\n"
     ]
    }
   ],
   "source": [
    "user_input = \"å¦‚ä½•ä½¿ç”¨LangGraphæ¥æ„å»ºä¸€ä¸ª AI æ™ºèƒ½ä½“ï¼Ÿè¯·ç»™å‡ºå…·ä½“çš„æ­¥éª¤ï¼Ÿ\"\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "events = graph.stream(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": user_input}]},\n",
    "    config,\n",
    "    stream_mode=\"values\",\n",
    ")\n",
    "for event in events:\n",
    "    if \"messages\" in event:\n",
    "        event[\"messages\"][-1].pretty_print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deepresearch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
